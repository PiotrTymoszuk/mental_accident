@misc{StatistikAustria2022,
author = {{Statistik Austria}},
keywords = {somatil_illness},
title = {{Gesundheitszustand selbstberichtet - STATISTIK AUSTRIA - Die Informationsmanager}},
url = {https://www.statistik.at/statistiken/bevoelkerung-und-soziales/gesundheit/gesundheitszustand/gesundheitszustand-selbstberichtet},
urldate = {2023-02-24},
year = {2022}
}
@misc{StatistikAustria2022a,
author = {{Statistik Austria}},
keywords = {smoking},
title = {{Rauchen - STATISTIK AUSTRIA - Die Informationsmanager}},
url = {https://www.statistik.at/statistiken/bevoelkerung-und-soziales/gesundheit/gesundheitsverhalten/rauchen},
urldate = {2023-02-24},
year = {2022}
}
@article{Tedeschi1996,
abstract = {The development of the Posttraumatic Growth Inventory, an instrument for assessing positive outcomes reported by persons who have experienced traumatic events, is described. This 21-item scale includes factors of New Possibilities, Relating to Others, Personal Strength, Spiritual Change, and Appreciation of Life. Women tend to report more benefits than do men, and persons who have experienced traumatic events report more positive change than do persons who have not experienced extraordinary events. The Posttraumatic Growth Inventory is modestly related to optimism and extraversion. The scale appears to have utility in determining how successful individuals, coping with the aftermath of trauma, are in reconstructing or strengthening their perceptions of self, others, and the meaning of events.},
author = {Tedeschi, Richard G. and Calhoun, Lawrence G.},
doi = {10.1007/BF02103658},
issn = {0894-9867},
journal = {Journal of traumatic stress},
keywords = {Adaptation,Adolescent,Adult,Female,Gender Identity,Humans,Interpersonal Relations,L G Calhoun,Life Change Events,MEDLINE,Male,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Personality Development,Personality Inventory / statistics & numerical dat,Philosophy,Post-Traumatic / diagnosis*,Post-Traumatic / psychology,Post-Traumatic / rehabilitation,Psychological*,PubMed Abstract,R G Tedeschi,Self Concept*,Social Perception*,Stress Disorders,doi:10.1007/BF02103658,pmid:8827649},
month = {jul},
number = {3},
pages = {455--471},
pmid = {8827649},
publisher = {J Trauma Stress},
title = {{The Posttraumatic Growth Inventory: measuring the positive legacy of trauma}},
url = {https://pubmed.ncbi.nlm.nih.gov/8827649/},
volume = {9},
year = {1996}
}
@article{Strobl2008,
abstract = {Background: Random forests are becoming increasingly popular in many scientific fields because they can cope with "small n large p" problems, complex interactions and even highly correlated predictor variables. Their variable importance measures have recently been suggested as screening tools for, e.g., gene expression studies. However, these variable importance measures show a bias towards correlated predictor variables. Results: We identify two mechanisms responsible for this finding: (i) A preference for the selection of correlated predictors in the tree building process and (ii) an additional advantage for correlated predictor variables induced by the unconditional permutation scheme that is employed in the computation of the variable importance measure. Based on these considerations we develop a new, conditional permutation scheme for the computation of the variable importance measure. Conclusion: The resulting conditional variable importance reflects the true impact of each predictor variable more reliably than the original marginal approach. {\textcopyright} 2008 Strobl et al; licensee BioMed Central Ltd.},
author = {Strobl, Carolin and Boulesteix, Anne Laure and Kneib, Thomas and Augustin, Thomas and Zeileis, Achim},
doi = {10.1186/1471-2105-9-307/FIGURES/4},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Algorithms,Bioinformatics,Computational Biology/Bioinformatics,Computer Appl. in Life Sciences,Microarrays},
month = {jul},
number = {1},
pages = {1--11},
pmid = {18620558},
publisher = {BioMed Central},
title = {{Conditional variable importance for random forests}},
url = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-9-307},
volume = {9},
year = {2008}
}
@article{Gennarelli2006,
abstract = {To determine and to quantify outcome from injury demands that multiple factors be universally applied so that there is uniform understanding that the same outcome is understood for the same injury. It is thus important to define the variables used in any outcome assessment. Critical to defining outcomes is the need for a universal language that defines individual injuries. The abbreviated injury scale (AIS) is the only dictionary specifically designed as a system to define the severity of injuries throughout the body. In addition to a universal injury language, it provides measures of injury severity that can be used to stratify and classify injury severity in all body regions. Its revision, AIS 2005 will be discussed here. {\textcopyright} 2006 Elsevier Ltd. All rights reserved.},
author = {Gennarelli, Thomas A. and Wodzin, Elaine},
doi = {10.1016/j.injury.2006.07.009},
issn = {00201383},
journal = {Injury},
keywords = {AIS,Injury scaling severity},
month = {dec},
number = {12},
pages = {1083--1091},
pmid = {17092503},
publisher = {Elsevier},
title = {{AIS 2005: A contemporary injury scale}},
url = {http://www.injuryjournal.com/article/S0020138306004190/fulltext http://www.injuryjournal.com/article/S0020138306004190/abstract https://www.injuryjournal.com/article/S0020-1383(06)00419-0/abstract},
volume = {37},
year = {2006}
}
@misc{VonJouanne-Diedrich2017,
abstract = {Implements the One Rule (OneR) Machine Learning classification algorithm (Holte, R.C. (1993) <doi:10.1023/A:1022631118932>) with enhancements for sophisticated handling of numeric data and missing values together with extensive diagnostic functions. It is useful as a baseline for machine learning models and the rules are often helpful heuristics.},
author = {von Jouanne-Diedrich, Holger},
title = {{OneR: One Rule Machine Learning Classification Algorithm with Enhancements}},
url = {https://cran.r-project.org/web/packages/OneR/index.html},
year = {2017}
}
@article{Holte1993,
abstract = {This article reports an empirical investigation of the accuracy of rules that classify examples on the basis of a single attribute. On most datasets studied, the best of these very simple rules is as accurate as the rules induced by the majority of machine learning systems. The article explores the implications of this finding for machine learning research and applications. {\textcopyright} 1993, Kluwer Academic Publishers. All rights reserved.},
author = {Holte, Robert C.},
doi = {10.1023/A:1022631118932/METRICS},
issn = {15730565},
journal = {Machine Learning},
keywords = {ID3,accuracy–complexity tradeoff,empirical learning,pruning},
number = {1},
pages = {63--90},
publisher = {Springer},
title = {{Very Simple Classification Rules Perform Well on Most Commonly Used Datasets}},
url = {https://link.springer.com/article/10.1023/A:1022631118932},
volume = {11},
year = {1993}
}
@article{Strobl2009,
abstract = {Recursive partitioning methods have become popular and widely used tools for nonparametric regression and classification in many scientific fields. Especially random forests, which can deal with large numbers of predictor variables even in the presence of complex interactions, have been applied successfully in genetics, clinical medicine, and bioinformatics within the past few years. High-dimensional problems are common not only in genetics, but also in some areas of psychological research, where only a few subjects can be measured because of time or cost constraints, yet a large amount of data is generated for each subject. Random forests have been shown to achieve a high prediction accuracy in such applications and to provide descriptive variable importance measures reflecting the impact of each variable in both main effects and interactions. The aim of this work is to introduce the principles of the standard recursive partitioning methods as well as recent methodological improvements, to illustrate their usage for low and high-dimensional data exploration, but also to point out limitations of the methods and potential pitfalls in their practical application. Application of the methods is illustrated with freely available implementations in the R system for statistical computing. {\textcopyright} 2009 American Psychological Association.},
author = {Strobl, Carolin and Malley, James and Tutz, Gerhard},
doi = {10.1037/A0016973},
issn = {1082989X},
journal = {Psychological methods},
keywords = {classification,prediction,regression,variable importance},
month = {dec},
number = {4},
pages = {323},
pmid = {19968396},
publisher = {NIH Public Access},
title = {{An Introduction to Recursive Partitioning: Rationale, Application and Characteristics of Classification and Regression Trees, Bagging and Random Forests}},
url = {/pmc/articles/PMC2927982/ /pmc/articles/PMC2927982/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2927982/},
volume = {14},
year = {2009}
}
@article{Strobl2007,
abstract = {Background: Variable importance measures for random forests have been receiving increased attention as a means of variable selection in many classification tasks in bioinformatics and related scientific fields, for instance to select a subset of genetic markers relevant for the prediction of a certain disease. We show that random forest variable importance measures are a sensible means for variable selection in many applications, but are not reliable in situations where potential predictor variables vary in their scale of measurement or their number of categories. This is particularly important in genomics and computational biology, where predictors often include variables of different types, for example when predictors include both sequence data and continuous variables such as folding energy, or when amino acid sequence data show different numbers of categories. Results: Simulation studies are presented illustrating that, when random forest variable importance measures are used with data of varying types, the results are misleading because suboptimal predictor variables may be artificially preferred in variable selection. The two mechanisms underlying this deficiency are biased variable selection in the individual classification trees used to build the random forest on one hand, and effects induced by bootstrap sampling with replacement on the other hand. Conclusion: We propose to employ an alternative implementation of random forests, that provides unbiased variable selection in the individual classification trees. When this method is applied using subsampling without replacement, the resulting variable importance measures can be used reliably for variable selection even in situations where the potential predictor variables vary in their scale of measurement or their number of categories. The usage of both random forest algorithms and their variable importance measures in the R system for statistical computing is illustrated and documented thoroughly in an application re-analyzing data from a study on RNA editing. Therefore the suggested method can be applied straightforwardly by scientists in bioinformatics research. {\textcopyright} 2007 Strobl et al; licensee BioMed Central Ltd.},
author = {Strobl, Carolin and Boulesteix, Anne Laure and Zeileis, Achim and Hothorn, Torsten},
doi = {10.1186/1471-2105-8-25/FIGURES/11},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Algorithms,Bioinformatics,Computational Biology/Bioinformatics,Computer Appl. in Life Sciences,Microarrays},
month = {jan},
number = {1},
pages = {1--21},
pmid = {17254353},
publisher = {BioMed Central},
title = {{Bias in random forest variable importance measures: Illustrations, sources and a solution}},
url = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-8-25},
volume = {8},
year = {2007}
}
@article{Hothorn2006,
abstract = {Recursive binary partitioning is a popular tool for regression analysis. Two fundamental problems of exhaustive search procedures usually applied to fit such models have been known for a long time: overfitting and a selection bias towards covariates with many possible splits or missing values. While pruning procedures are able to solve the overfitting problem, the variable selection bias still seriously affects the interpretability of tree-structured regression models. For some special cases unbiased procedures have been suggested, however lacking a common theoretical foundation. We propose a unified framework for recursive partitioning which embeds tree-structured regression models into a well defined theory of conditional inference procedures. Stopping criteria based on multiple test procedures are implemented and it is shown that the predictive performance of the resulting trees is as good as the performance of established exhaustive search procedures. It turns out that the partitions and therefore the models induced by both approaches are structurally different, confirming the need for an unbiased variable selection. Moreover, it is shown thai the prediction accuracy of trees with early stopping is equivalent to the prediction accuracy of pruned trees with unbiased variable selection. The methodology presented here is applicable to all kinds of regression problems, including nominal, ordinal, numeric, censored as well as multivariate response variables and arbitrary measurement scales of the covariates. Data from studies on glaucoma classification, node positive breast cancer survival and mammography experience are re-analyzed. {\textcopyright} 2006 American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America.},
author = {Hothorn, Torsten and Hornik, Kurt and Zeileis, Achim},
doi = {10.1198/106186006X133933},
issn = {10618600},
journal = {Journal of Computational and Graphical Statistics},
keywords = {Multiple testing,Multivariate regression trees,Ordinal regression trees,Permutation tests,Variable selection},
number = {3},
pages = {651--674},
publisher = {Taylor & Francis},
title = {{Unbiased recursive partitioning: A conditional inference framework}},
url = {https://www.tandfonline.com/doi/abs/10.1198/106186006X133933},
volume = {15},
year = {2006}
}
@misc{Hothorn2022,
abstract = {A computational toolbox for recursive partitioning. The core of the package is ctree(), an implementation of conditional inference trees which embed tree-structured regression models into a well defined theory of conditional inference procedures. This non-parametric class of regression trees is applicable to all kinds of regression problems, including nominal, ordinal, numeric, censored as well as multivariate response variables and arbitrary measurement scales of the covariates. Based on conditional inference trees, cforest() provides an implementation of Breiman's random forests. The function mob() implements an algorithm for recursive partitioning based on parametric models (e.g. linear models, GLMs or survival regression) employing parameter instability tests for split selection. Extensible functionality for visualizing tree-structured regression models is available. The methods are described in Hothorn et al. (2006) <doi:10.1198/106186006X133933>, Zeileis et al. (2008) <doi:10.1198/106186008X319331> and Strobl et al. (2007) <doi:10.1186/1471-2105-8-25>.},
author = {Hothorn, Thorsten and Hornik, Kurt and Strobl, Carolin and Zeileis, Achim},
title = {{party: A Laboratory for Recursive Partytioning}},
url = {https://cran.r-project.org/web/packages/party/index.html},
year = {2022}
}
@article{Croux2007,
abstract = {The results of a standard principal component analysis (PCA) can be affected by the presence of outliers. Hence robust alternatives to PCA are needed. One of the most appealing robust methods for principal component analysis uses the Projection-Pursuit principle. Here, one projects the data on a lower-dimensional space such that a robust measure of variance of the projected data will be maximized. The Projection-Pursuit-based method for principal component analysis has recently been introduced in the field of chemometrics, where the number of variables is typically large. In this paper, it is shown that the currently available algorithm for robust Projection-Pursuit PCA performs poor in the presence of many variables. A new algorithm is proposed that is more suitable for the analysis of chemical data. Its performance is studied by means of simulation experiments and illustrated on some real data sets. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Croux, C. and Filzmoser, P. and Oliveira, M. R.},
doi = {10.1016/j.chemolab.2007.01.004},
issn = {01697439},
journal = {Chemometrics and Intelligent Laboratory Systems},
keywords = {Multivariate statistics,Numerical precision,Optimization,Outliers,Robustness,Scale estimators},
month = {jun},
number = {2},
pages = {218--225},
publisher = {Elsevier},
title = {{Algorithms for Projection-Pursuit robust principal component analysis}},
volume = {87},
year = {2007}
}
@misc{Kassambara2020,
author = {Kassambara, Alboukadel and Mundt, Fabian},
title = {{factoextra: Extract and Visualize the Results of Multivariate Data Analyses}},
url = {https://cran.r-project.org/web/packages/factoextra/index.html},
year = {2020}
}
@inproceedings{Schubert2019,
abstract = {Clustering non-Euclidean data is difficult, and one of the most used algorithms besides hierarchical clustering is the popular algorithm Partitioning Around Medoids (PAM), also simply referred to as k-medoids. In Euclidean geometry the mean—as used in k-means—is a good estimator for the cluster center, but this does not exist for arbitrary dissimilarities. PAM uses the medoid instead, the object with the smallest dissimilarity to all others in the cluster. This notion of centrality can be used with any (dis-)similarity, and thus is of high relevance to many domains and applications. A key issue with PAM is its high run time cost. We propose modifications to the PAM algorithm that achieve an O(k)-fold speedup in the second (“SWAP”) phase of the algorithm, but will still find the same results as the original PAM algorithm. If we slightly relax the choice of swaps performed (while retaining comparable quality), we can further accelerate the algorithm by performing up to k swaps in each iteration. With the substantially faster SWAP, we can now explore faster intialization strategies. We also show how the CLARA and CLARANS algorithms benefit from the proposed modifications.},
archivePrefix = {arXiv},
arxivId = {1810.05691},
author = {Schubert, Erich and Rousseeuw, Peter J.},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-030-32047-8_16},
eprint = {1810.05691},
isbn = {9783030320461},
issn = {16113349},
keywords = {CLARA,CLARANS,Cluster analysis,PAM,k-Medoids},
month = {oct},
pages = {171--187},
publisher = {Springer},
title = {{Faster k-Medoids Clustering: Improving the PAM, CLARA, and CLARANS Algorithms}},
url = {https://link.springer.com/chapter/10.1007/978-3-030-32047-8_16},
volume = {11807 LNCS},
year = {2019}
}
@misc{Gagolewski2021,
abstract = {A collection of character string/text/natural language processing tools for pattern searching (e.g., with 'Java'-like regular expressions or the 'Unicode' collation algorithm), random string generation, case mapping, string transliteration, concatenation, sorting, padding, wrapping, Unicode normalisation, date-time formatting and parsing, and many more. They are fast, consistent, convenient, and - thanks to 'ICU' (International Components for Unicode) - portable across all locales and platforms.},
author = {Gagolewski, Marek and Tartanus, Bartek},
title = {{Package 'stringi'}},
url = {https://cran.r-project.org/web/packages/stringi/index.html http://cran.ism.ac.jp/web/packages/stringi/stringi.pdf},
year = {2021}
}
@misc{Vaughan2022,
abstract = {Implementations of the family of map() functions from 'purrr' that can be resolved using any 'future'-supported backend, e.g. parallel on the local machine or distributed on a compute cluster.},
author = {Vaughan, Davis and Dancho, Matt and RStudio},
month = {aug},
publisher = {Comprehensive R Archive Network (CRAN)},
title = {{furrr: Apply Mapping Functions in Parallel using Futures}},
url = {https://cran.r-project.org/package=furrr},
year = {2022}
}
@article{Wickham2019,
abstract = {At a high level, the tidyverse is a language for solving data science challenges with R code. Its primary goal is to facilitate a conversation between a human and a computer about data. Less abstractly, the tidyverse is a collection of R packages that share a high-level design philosophy and low-level grammar and data structures, so that learning one package makes it easier to learn the next. The tidyverse encompasses the repeated tasks at the heart of every data science project: data import, tidying, manipulation, visualisation, and programming. We expect that almost every project will use multiple domain-specific packages outside of the tidyverse: our goal is to provide tooling for the most common challenges; not to solve every possible problem. Notably, the tidyverse doesn't include tools for statistical modelling or communication. These toolkits are critical for data science, but are so large that they merit separate treatment. The tidyverse package allows users to install all tidyverse packages with a single command. There are a number of projects that are similar in scope to the tidyverse. The closest is perhaps Bioconductor (Gentleman et al., 2004; Huber et al., 2015), which provides an ecosystem of packages that support the analysis of high-throughput genomic data.},
author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and McGowan, Lucy and Fran{\c{c}}ois, Romain and Grolemund, Garrett and Hayes, Alex and Henry, Lionel and Hester, Jim and Kuhn, Max and Pedersen, Thomas and Miller, Evan and Bache, Stephan and M{\"{u}}ller, Kirill and Ooms, Jeroen and Robinson, David and Seidel, Dana and Spinu, Vitalie and Takahashi, Kohske and Vaughan, Davis and Wilke, Claus and Woo, Kara and Yutani, Hiroaki},
doi = {10.21105/joss.01686},
file = {:C\:/Users/piotr/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wickham et al. - 2019 - Welcome to the Tidyverse.pdf:pdf},
issn = {2475-9066},
journal = {Journal of Open Source Software},
month = {nov},
number = {43},
pages = {1686},
publisher = {The Open Journal},
title = {{Welcome to the Tidyverse}},
volume = {4},
year = {2019}
}
@misc{Signorell2022,
abstract = {A collection of miscellaneous basic statistic functions and convenience wrappers for efficiently describing data. The author's intention was to create a toolbox, which facilitates the (notoriously time consuming) first descriptive tasks in data analysis, consisting of calculating descriptive statistics, drawing graphical summaries and reporting the results. The package contains furthermore functions to produce documents using MS Word (or PowerPoint) and functions to import data from Excel. Many of the included functions can be found scattered in other packages and other sources written partly by Titans of R. The reason for collecting them here, was primarily to have them consolidated in ONE instead of dozens of packages (which themselves might depend on other packages which are not needed at all), and to provide a common and consistent interface as far as function and arguments naming, NA handling, recycling rules etc. are concerned. Google style guides were used as naming rules (in absence of convincing alternatives). The 'BigCamelCase' style was consequently applied to functions borrowed from contributed R packages as well.},
author = {Signorell, Andri},
month = {oct},
publisher = {Comprehensive R Archive Network (CRAN)},
title = {{DescTools: Tools for Descriptive Statistics}},
url = {https://cran.r-project.org/package=DescTools},
year = {2022}
}
@misc{LePennec2019,
abstract = {Provides a word cloud text geom for 'ggplot2'. Texts are placed so that they do not overlap as in 'ggrepel'. The algorithm used is a variation around the one of 'wordcloud2.js'.},
author = {{Le Pennec}, Erwan and Slowikowski, Kamil},
month = {jun},
publisher = {Comprehensive R Archive Network (CRAN)},
title = {{A Word Cloud Geom for 'ggplot2' [R package ggwordcloud version 0.5.0]}},
url = {https://cran.r-project.org/package=ggwordcloud},
year = {2019}
}
@book{McDonald1999,
abstract = {This book introduces the reader to the main quantitative concepts, methods, and computational techniques needed for the development, evaluation, and application of tests in the behavioral/social sciences, including educational tests. Two empirical examples are carried throughout to illustrate alternative methods. Other data sets are used for special illustrations. Self-contained programs for confirmatory and exploratory factor analysis are available on the Web. Intended for students of psychology, particularly educational psychology, as well as social science students interested in how tests are constructed and used, prerequisites include a course on statistics.},
address = {New Yor},
author = {McDonald, Roderick P.},
booktitle = {Test Theory: A Unified Treatment},
doi = {10.4324/9781410601087},
edition = {1st Editio},
isbn = {9781410601087},
month = {jul},
pages = {1--485},
publisher = {Psychology Press},
title = {{Test theory: A unified treatment}},
url = {https://www.taylorfrancis.com/books/mono/10.4324/9781410601087/test-theory-roderick-mcdonald},
year = {1999}
}
@article{Becht2018,
abstract = {Advances in single-cell technologies have enabled high-resolution dissection of tissue composition. Several tools for dimensionality reduction are available to analyze the large number of parameters generated in single-cell studies. Recently, a nonlinear dimensionality-reduction technique, uniform manifold approximation and projection (UMAP), was developed for the analysis of any type of high-dimensional data. Here we apply it to biological data, using three well-characterized mass cytometry and single-cell RNA sequencing datasets. Comparing the performance of UMAP with five other tools, we find that UMAP provides the fastest run times, highest reproducibility and the most meaningful organization of cell clusters. The work highlights the use of UMAP for improved visualization and interpretation of single-cell data.},
author = {Becht, Etienne and McInnes, Leland and Healy, John and Dutertre, Charles Antoine and Kwok, Immanuel W.H. and Ng, Lai Guan and Ginhoux, Florent and Newell, Evan W.},
doi = {10.1038/nbt.4314},
issn = {15461696},
journal = {Nature Biotechnology},
keywords = {Computational biology and bioinformatics,Data mining,Immunology},
month = {dec},
number = {1},
pages = {38--47},
pmid = {30531897},
publisher = {Nature Publishing Group},
title = {{Dimensionality reduction for visualizing single-cell data using UMAP}},
url = {https://www.nature.com/articles/nbt.4314},
volume = {37},
year = {2019}
}
@article{Kroenke2002,
abstract = {Objective: Somatization is prevalent in primary care and is associated with substantial functional impairment and healthcare utilization. However, instruments for identifying and monitoring somatic symptoms are few in number and not widely used. Therefore, we examined the validity of a brief measure of the severity of somatic symptoms. Methods: The Patient Health Questionnaire (PHQ) is a self-administered version of the PRIME-MD diagnostic instrument for common mental disorders. The PHQ-15 comprises 15 somatic symptoms from the PHQ, each symptom scored from 0 ("not bothered at all") to 2 ("bothered a lot"). The PHQ-15 was administered to 6000 patients in eight general internal medicine and family practice clinics and seven obstetrics-gynecology clinics. Outcomes included functional status as assessed by the 20-item Short-Form General Health Survey (SF-20), self-reported sick days and clinic visits, and symptom-related difficulty. Results: As PHQ-15 somatic symptom severity increased, there was a substantial stepwise decrement in functional status on all six SF-20 subscales. Also, symptom-related difficulty, sick days, and healthcare utilization increased. PHQ-15 scores of 5, 10, 15, represented cutoff points for low, medium, and high somatic symptom severity, respectively. Somatic and depressive symptom severity had differential effects on outcomes. Results were similar in the primary care and obstetrics-gynecology samples. Conclusions: The PHQ-15 is a brief, self-administered questionnaire that may be useful in screening for somatization and in monitoring somatic symptom severity in clinical practice and research.},
author = {Kroenke, Kurt and Spitzer, Robert L. and Williams, Janet B.W.},
doi = {10.1097/00006842-200203000-00008},
issn = {0033-3174},
journal = {Psychosomatic medicine},
keywords = {Adult,Aged,Depression / diagnosis,Depression / psychology,Diagnosis,Differential,Family Practice,Female,Humans,Internal Medicine,Janet B W Williams,Kurt Kroenke,MEDLINE,Male,Middle Aged,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Non-U.S. Gov't,Patient Care Team,Personality Inventory / statistics & numerical dat,Pregnancy,Psychometrics,PubMed Abstract,Reproducibility of Results,Research Support,Robert L Spitzer,Somatoform Disorders / diagnosis*,Somatoform Disorders / psychology,doi:10.1097/00006842-200203000-00008,pmid:11914441},
number = {2},
pages = {258--266},
pmid = {11914441},
publisher = {Psychosom Med},
title = {{The PHQ-15: validity of a new measure for evaluating the severity of somatic symptoms}},
url = {https://pubmed.ncbi.nlm.nih.gov/11914441/},
volume = {64},
year = {2002}
}
@misc{Gohel2022,
abstract = {Create pretty tables for 'HTML', 'PDF', 'Microsoft Word' and 'Microsoft PowerPoint' documents from 'R Markdown'. Functions are provided to let users create tables, modify and format their content. It also extends package 'officer' that does not contain any feature for customized tabular reporting.},
author = {Gohel, David},
title = {{flextable: Functions for Tabular Reporting}},
url = {https://cran.r-project.org/web/packages/flextable/index.html},
year = {2022}
}
@article{OBrien2008,
abstract = {Four clinical interview questions, the CAGE questions, have proved useful in helping to make a diagnosis of alcoholism. The questions focus on Cutting down, Annoyance by criticism, Guilty feeling, and Eye-openers. The acronym “CAGE” helps the physician to recall the questions.How these questions were identified and their use in clinical and research studies are described.See PDF for full text of the original JAMA article.},
author = {O'Brien, Charles P.},
doi = {10.1001/JAMA.2008.570},
issn = {0098-7484},
journal = {JAMA},
keywords = {alcohol dependence,alcohol use test},
month = {nov},
number = {17},
pages = {2054--2056},
pmid = {18984895},
publisher = {American Medical Association},
title = {{The CAGE Questionnaire for Detection of Alcoholism}},
url = {https://jamanetwork.com/journals/jama/fullarticle/182810},
volume = {300},
year = {2008}
}
@article{Spitzer2006,
abstract = {Background Generalized anxiety disorder (GAD) is one of the most common mental disorders; however, there is no brief clinical measure for assessing GAD. The objective of this study was to develop a brief self-report scale to identify probable cases of GAD and evaluate its reliability and validity. Methods A criterion-standard study was performed in 15 primary care clinics in the United States from November 2004 through June 2005. Of a total of 2740 adult patients completing a study questionnaire, 965 patients had a telephone interview with a mental health professional within 1 week. For criterion and construct validity, GAD self-report scale diagnoses were compared with independent diagnoses made by mental health professionals; functional status measures; disability days; and health care use. Results A 7-item anxiety scale (GAD-7) had good reliability, as well as criterion, construct, factorial, and procedural validity. A cut point was identified that optimized sensitivity (89%) and specificity (82%). Increasing scores on the scale were strongly associated with multiple domains of functional impairment (all 6 Medical Outcomes Study Short-Form General Health Survey scales and disability days). Although GAD and depression symptoms frequently co-occurred, factor analysis confirmed them as distinct dimensions. Moreover, GAD and depression symptoms had differing but independent effects on functional impairment and disability. There was good agreement between self-report and interviewer-administered versions of the scale. Conclusion The GAD-7 is a valid and efficient tool for screening for GAD and assessing its severity in clinical practice and research.},
author = {Spitzer, Robert L. and Kroenke, Kurt and Williams, Janet B.W. and L{\"{o}}we, Bernd},
doi = {10.1001/ARCHINTE.166.10.1092},
issn = {0003-9926},
journal = {Archives of Internal Medicine},
keywords = {anxiety,depressive disorders,generalized anxiety disorder},
month = {may},
number = {10},
pages = {1092--1097},
pmid = {16717171},
publisher = {American Medical Association},
title = {{A Brief Measure for Assessing Generalized Anxiety Disorder: The GAD-7}},
url = {https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/410326},
volume = {166},
year = {2006}
}
@article{Leng2014,
abstract = {Semi-supervised clustering which uses the limited labeled data to aid unsupervised clustering, has become a hot topic in recent years. But the limited labeled data may be imbalanced and can not cover all clusters in some cases and most of the existing semi-supervised clustering algorithms can not deal with imbalanced dataset well and have no the ability of detecting new clusters. In view of this, an adaptive semi-supervised clustering algorithm with label propagation is proposed. Two most of interesting characteristics of the proposed algorithm are that (1) It uses the limited labeled data to expand labeled dataset based on an adaptive threshold by labeling their k-nearest neighbors, (2) It detects whether there exist new clusters in the unlabeled dataset according to a proposed measure criterion. Three standard datasets are used to demonstrate the performance of the proposed algorithm and the experimental results confirm that the accuracy of the proposed clustering algorithm is much higher than that of three compared algorithm and in addition the proposed algorithm has the ability of detecting new clusters. {\textcopyright} 2014 Academic Journals Inc.},
author = {Leng, Mingwei and Wang, Jinjin and Cheng, Jianjun and Zhou, Hanhai and Chen, Xiaoyun},
doi = {10.3923/jse.2014.14.22},
file = {:C\:/Users/piotr/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Leng et al. - 2014 - Adaptive semi-supervised clustering algorithm with label propagation.pdf:pdf},
issn = {21520941},
journal = {Journal of Software Engineering},
keywords = {Data mining,K-nearest neighbors,Label propagation,Semi-supervised clustering},
number = {1},
pages = {14--22},
publisher = {Academic Journals},
title = {{Adaptive semi-supervised clustering algorithm with label propagation}},
volume = {8},
year = {2014}
}
@article{McInnes2018,
abstract = {UMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension reduction. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic topology. The result is a practical scalable algorithm that applies to real world data. The UMAP algorithm is competitive with t-SNE for visualization quality, and arguably preserves more of the global structure with superior run time performance. Furthermore, UMAP has no computational restrictions on embedding dimension, making it viable as a general purpose dimension reduction technique for machine learning.},
archivePrefix = {arXiv},
arxivId = {1802.03426},
author = {McInnes, Leland and Healy, John and Melville, James},
eprint = {1802.03426},
month = {feb},
title = {{UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction}},
url = {https://arxiv.org/abs/1802.03426v3 http://arxiv.org/abs/1802.03426},
year = {2018}
}
@article{Manea2012,
abstract = {Background: The brief Patient Health Questionnaire (PHQ-9) is commonly used to screen for depression with 10 often recommended as the cut-off score. We summarized the psychometric properties of the PHQ-9 across a range of studies and cut-off scores to select the optimal cut-off for detecting depression. Methods: We searched Embase, MEDLINE and PsycINFO from 1999 to August 2010 for studies that reported the diagnostic accuracy of PHQ-9 to diagnose major depressive disorders. We calculated summary sensitivity, specificity, likelihood ratios and diagnostic odds ratios for detecting major depressive disorder at different cut-off scores and in different settings. We used random-effects bivariate meta-analysis at cut-off points between 7 and 15 to produce summary receiver operating characteristic curves. Results: We identified 18 validation studies (n = 7180) conducted in various clinical settings. Eleven studies provided details about the diagnostic properties of the questionnaire at more than one cut-off score (including 10), four studies reported a cut-off score of 10, and three studies reported cut-off scores other than 10. The pooled specificity results ranged from 0.73 (95% confidence interval [CI] 0.63-0.82) for a cut-off score of 7 to 0.96 (95% CI 0.94-0.97) for a cut-off score of 15. There was major variability in sensitivity for cut-off scores between 7 and 15. There were no substantial differences in the pooled sensitivity and specificity for a range of cut-off scores (8-11). Interpretation: The PHQ-9 was found to have acceptable diagnostic properties for detecting major depressive disorder for cut-off scores between 8 and 11. Authors of future validation studies should consistently report the outcomes for different cut-off scores. {\textcopyright} 2012 Canadian Medical Association or its licensors.},
author = {Manea, Laura and Gilbody, Simon and McMillan, Dean},
doi = {10.1503/CMAJ.110829/-/DC1},
issn = {14882329},
journal = {CMAJ},
month = {feb},
number = {3},
pages = {E191},
pmid = {22184363},
publisher = {Canadian Medical Association},
title = {{Optimal cut-off score for diagnosing depression with the Patient Health Questionnaire (PHQ-9): A meta-analysis}},
url = {/pmc/articles/PMC3281183/ /pmc/articles/PMC3281183/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3281183/},
volume = {184},
year = {2012}
}
@article{Vesanto2000,
abstract = {The self-organizing map (SOM) is an excellent tool in exploratory phase of data mining. It projects input space on prototypes of a low-dimensional regular grid that can be effectively utilized to visualize and explore properties of the data. When the number of SOM units is large, to facilitate quantitative analysis of the map and the data, similar units need to be grouped, i.e., clustered. In this paper, different approaches to clustering of the SOM are considered. In particular, the use of hierarchical agglomerative clustering and partitive clustering using k-means are investigated. The two-stage procedure-first using SOM to produce the prototypes that are then clustered in the second stage-is found to perform well when compared with direct clustering of the data and to reduce the computation time.},
author = {Vesanto, Juha and Alhoniemi, Esa},
doi = {10.1109/72.846731},
issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
month = {may},
number = {3},
pages = {586--600},
title = {{Clustering of the self-organizing map}},
volume = {11},
year = {2000}
}
@book{Xie2016,
abstract = {bookdown: Authoring Books and Technical Documents with R Markdown presents a much easier way to write books and technical publications than traditional tools such as LaTeX and Word. The bookdown package inherits the simplicity of syntax and flexibility for data analysis from R Markdown, and extends R Markdown for technical writing, so that you can make better use of document elements such as figures, tables, equations, theorems, citations, and references. Similar to LaTeX, you can number and cross-reference these elements with bookdown. Your document can even include live examples so readers can interact with them while reading the book. The book can be rendered to multiple output formats, including LaTeX/PDF, HTML, EPUB, and Word, thus making it easy to put your documents online. The style and theme of these output formats can be customized. We used books and R primarily for examples in this book, but bookdown is not only for books or R. Most features introduced in this book also apply to other types of publications: journal papers, reports, dissertations, course handouts, study notes, and even novels. You do not have to use R, either. Other choices of computing languages include Python, C, C plus plus, SQL, Bash, Stan, JavaScript, and so on, although R is best supported. You can also leave out computing, for example, to write a fiction. This book itself is an example of publishing with bookdown and R Markdown, and its source is fully available on GitHub.},
author = {Xie, Yihui},
booktitle = {Bookdown: Authoring Books and Technical Documents with R Markdown},
doi = {10.1201/9781315204963},
isbn = {9781351792608},
pages = {1--113},
title = {{Bookdown: Authoring books and technical documents with R Markdown}},
year = {2016}
}
@misc{Wilke2022,
abstract = {A 'ggplot2' extension that enables the rendering of complex formatted plot labels (titles, subtitles, facet labels, axis labels, etc.). Text boxes with automatic word wrap are also supported.},
author = {Wilke, Claus O and Wiernik, Brenton M},
month = {sep},
publisher = {Comprehensive R Archive Network (CRAN)},
title = {{ggtext: Improved Text Rendering Support for 'ggplot2'}},
url = {https://cran.r-project.org/package=ggtext},
year = {2022}
}
@article{Kuhn2008,
abstract = {The caret package, short for classification and regression training, contains numerous tools for developing predictive models using the rich set of models available in R. The package focuses on simplifying model training and tuning across a wide variety of modeling techniques. It also includes methods for pre-processing training data, calculating variable importance, and model visualizations. An example from computational chemistry is used to illustrate the functionality on a real data set and to benchmark the benefits of parallel processing with several types of models.},
author = {Kuhn, Max},
doi = {10.18637/jss.v028.i05},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {Model building,NetWorkSpaces,Parallel processing,R,Tuning parameters},
number = {5},
pages = {1--26},
publisher = {American Statistical Association},
title = {{Building predictive models in R using the caret package}},
volume = {28},
year = {2008}
}
@article{Grafe2004,
abstract = {The aim of this study was to validate the German version of the "Patient Health Questionnaire (PHQ)". The PHQ has been developed to screen for mental disorders in primary care, using diagnostic criteria from the DSM-IV. Three hundred and fifty-seven medical outpatients and 171 psychosomatic outpatients completed the PHQ and the Structured Clinical Interview for DSM-IV (SCID), the latter serving as criterion standard. Acceptability of the PHQ as the screening instrument was investigated for physicians and patients. For the diagnosis of major depressive disorder, the PHQ showed excellent criterion validity (medical patients: sensitivity, 95%; specificity, 86%). Good operating characteristics were also found for the diagnosis of panic disorder. The use of the PHQ was well accepted by more than 90% of both physicians and patients. Overall, the PHQ is a valid, effective, and well accepted diagnostic tool for use in research and clinical practice. Its' application in primary care and other clinical settings might contribute to better diagnosis and treatment of mental disorders.},
author = {Gr{\"{a}}fe, Kerstin and Zipfel, Stephan and Herzog, Wolfgang and L{\"{o}}we, Bernd},
doi = {10.1026/0012-1924.50.4.171},
issn = {00121924},
journal = {Diagnostica},
keywords = {Mental disorders,Primary care,Psychosomatic medicine,Screening test,Validity},
month = {oct},
number = {4},
pages = {171--181},
publisher = { Hogrefe Verlag G{\"{o}}ttingen },
title = {{Screening psychischer st{\"{o}}rungen mit dem "Gesundheitsfragebogen f{\"{u}}r Patienten (PHQ-D)". Ergebnisse der Deutschen validierungsstudie}},
url = {https://econtent.hogrefe.com/doi/abs/10.1026/0012-1924.50.4.171},
volume = {50},
year = {2004}
}
@misc{Konopka2022,
abstract = {Uniform manifold approximation and projection is a technique for dimension reduction. The algorithm was described by McInnes and Healy (2018) in <arXiv:1802.03426>. This package provides an interface for two implementations. One is written from scratch, including components for nearest-neighbor search and for embedding. The second implementation is a wrapper for 'python' package 'umap-learn' (requires separate installation, see vignette for more details).},
author = {Konopka, Tomasz},
title = {{umap: Uniform Manifold Approximation and Projection}},
url = {https://cran.r-project.org/web/packages/umap/index.html},
year = {2022}
}
@article{Benjamini1995,
abstract = {The common approach to the multiplicity problem calls for controlling the familywise error rate (FWER). This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses- the false discovery rate. This error rate is equivalent to the FWER when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the FWER is desired, there is potential for a gain in power. A simple sequential Bonferronitype procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.},
author = {Benjamini, Yoav and Hochberg, Yosef},
doi = {10.1111/j.2517-6161.1995.tb02031.x},
issn = {0035-9246},
journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
keywords = {bonferroni‐type procedures,familywise error rate,multiple‐comparison procedures,p‐values},
month = {jan},
number = {1},
pages = {289--300},
publisher = {Wiley},
title = {{Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing}},
volume = {57},
year = {1995}
}
@techreport{Lowe2002,
author = {L{\"{o}}we, Bernd and Spitzer, Robert L and Zipfel, Stephan and Herzog, Wolfgang},
file = {:C\:/Users/piotr/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/L{\"{o}}we et al. - 2002 - Auflage Manual 17.07.pdf:pdf},
pages = {44--45},
title = {{Auflage Manual 17.07}},
volume = {9},
year = {2002}
}
@misc{Allaire2022,
abstract = {Convert R Markdown documents into a variety of formats.},
author = {Allaire, JJ and Xie, Yihui and McPherson, Jonathan and Luraschi, Javier and Ushey, Kevin and Atkins, Aron and Wickham, Hadley and Cheng, Joe},
title = {{rmarkdown: Dynamic Documents for R}},
url = {https://cran.r-project.org/web/packages/rmarkdown/index.html},
year = {2022}
}
@article{Schumacher2000,
abstract = {In this article we will describe the evaluation of Antonovsky's 29-items Sense of Coherence Scale (SOC-29) in a large community sample (n = 2.005) of the German population and the development of the Leipzig Short Scale (SOC-L9), which consists of only 9 items. The SOC-29 has a high internal consistency ($\alpha$ = 0.92), however, the SOC-subscales (comprehensibility, manageability, meaningfulness) were correlated with each other. A principal component factor analysis did not identify the 3-factor structure of the SOC-Scale. It appears that the best solution consists of one global factor. The newly developed SOC-L9, conceptualized as an unidimensional scale, is a reliable and valid instrument, which allows to assess the SOC economically. In our study the Sense of Coherence depended on age and gender. Women and older people reported a lower SOC. Furthermore we found significant associations between SOC and different subjective health measures. A high SOC was associated with both a lower extent of subjective body complaints and somatoform symptoms and with minor health-related problems in daily living.},
author = {Schumacher, J. and Wilz, G. and Gunzelmann, T. and Br{\"{a}}hler, E.},
doi = {10.1055/s-2000-9207},
issn = {09372032},
journal = {PPmP Psychotherapie Psychosomatik Medizinische Psychologie},
keywords = {New short scale,Salutogenic model,Sense of Coherence Scale (SOC),Sense of coherence},
number = {12},
pages = {472--482},
pmid = {11199111},
publisher = {Psychother Psychosom Med Psychol},
title = {{Die sense of coherence scale von antonovsky: Teststatische {\"{u}}berpr{\"{u}}fung in einer repr{\"{a}}sentativen bev{\"{o}}lkerungsstichprobe und konstruktion einer kurzskala}},
url = {https://pubmed.ncbi.nlm.nih.gov/11199111/},
volume = {50},
year = {2000}
}
@book{Wilke2019,
abstract = {First edition. Intro; Copyright; Table of Contents; Preface; Thoughts on Graphing Software and Figure-Preparation Pipelines; Conventions Used in This Book; Using Code Examples; O'Reilly Online Learning; How to Contact Us; Acknowledgments; Chapter 1. Introduction; Ugly, Bad, and Wrong Figures; Part I. From Data to Visualization; Chapter 2. Visualizing Data: Mapping Data onto Aesthetics; Aesthetics and Types of Data; Scales Map Data Values onto Aesthetics; Chapter 3. Coordinate Systems and Axes; Cartesian Coordinates; Nonlinear Axes; Coordinate Systems with Curved Axes; Chapter 4. Color Scales Color as a Tool to DistinguishColor to Represent Data Values; Color as a Tool to Highlight; Chapter 5. Directory of Visualizations; Amounts; Distributions; Proportions; x-y relationships; Geospatial Data; Uncertainty; Chapter 6. Visualizing Amounts; Bar Plots; Grouped and Stacked Bars; Dot Plots and Heatmaps; Chapter 7. Visualizing Distributions: Histograms and Density Plots; Visualizing a Single Distribution; Visualizing Multiple Distributions at the Same Time; Chapter 8. Visualizing Distributions: Empirical Cumulative Distribution Functions and Q-Q Plots Empirical Cumulative Distribution FunctionsHighly Skewed Distributions; Quantile-Quantile Plots; Chapter 9. Visualizing Many Distributions at Once; Visualizing Distributions Along the Vertical Axis; Visualizing Distributions Along the Horizontal Axis; Chapter 10. Visualizing Proportions; A Case for Pie Charts; A Case for Side-by-Side Bars; A Case for Stacked Bars and Stacked Densities; Visualizing Proportions Separately as Parts of the Total; Chapter 11. Visualizing Nested Proportions; Nested Proportions Gone Wrong; Mosaic Plots and Treemaps; Nested Pies; Parallel Sets Chapter 12. Visualizing Associations Among Two or More Quantitative VariablesScatterplots; Correlograms; Dimension Reduction; Paired Data; Chapter 13. Visualizing Time Series and Other Functions of an Independent Variable; Individual Time Series; Multiple Time Series and Dose-Response Curves; Time Series of Two or More Response Variables; Chapter 14. Visualizing Trends; Smoothing; Showing Trends with a Defined Functional Form; Detrending and Time-Series Decomposition; Chapter 15. Visualizing Geospatial Data; Projections; Layers; Choropleth Mapping; Cartograms Chapter 16. Visualizing UncertaintyFraming Probabilities as Frequencies; Visualizing the Uncertainty of Point Estimates; Visualizing the Uncertainty of Curve Fits; Hypothetical Outcome Plots; Part II. Principles of Figure Design; Chapter 17. The Principle of Proportional Ink; Visualizations Along Linear Axes; Visualizations Along Logarithmic Axes; Direct Area Visualizations; Chapter 18. Handling Overlapping Points; Partial Transparency and Jittering; 2D Histograms; Contour Lines; Chapter 19. Common Pitfalls of Color Use; Encoding Too Much or Irrelevant Information},
address = {Sebastopol},
author = {Wilke, Claus O},
booktitle = {O'Reilly Media},
edition = {1},
isbn = {1492031089},
pages = {389},
publisher = {O'Reilly Media},
title = {{Fundamentals of Data Visualization: A Primer on Making Informative and Compelling Figures}},
year = {2019}
}
@misc{Kassambara2021,
author = {Kassambara, Alboukadel},
title = {{rstatix: Pipe-Friendly Framework for Basic Statistical Tests}},
url = {https://cran.r-project.org/package=rstatix},
year = {2021}
}
@misc{RCoreTeam,
abstract = {Reading and writing data stored by some versions of 'Epi Info', 'Minitab', 'S', 'SAS', 'SPSS', 'Stata', 'Systat', 'Weka', and for reading and writing some 'dBase' files.},
author = {{R Core Team} and Bivand, Roger and Carey, Vincent J and DebRoy, Saikat and Eglen, Stephen and Guha, Rajarshi and Herbrandt, Swetlana and Lewin-Koh, Nicholas and Myatt, Mark and Nelson, Michael and Pfaff, Ben and Quistorff, Brian and Warmerdam, Frank and Weigand, Stephen and {Free Software Foundation}, Inc.},
title = {{foreign: Read Data Stored by 'Minitab', 'S', 'SAS', 'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ...}},
url = {https://cran.r-project.org/web/packages/foreign/index.html},
year = {2022}
}
@article{Sinclair2004,
abstract = {This article introduces the Brief Resilient Coping Scale (BRCS), a 4-item measure designed to capture tendencies to cope with stress in a highly adaptive manner. Two samples of individuals with rheumatoid arthritis (ns = 90 and 140) provide evidence for the reliability and validity of the BRCS. The BRCS has adequate internal consistency and test-re test reliability. Convergent validity of the scale is demonstrated by predictable correlations with measures of personal coping resources (e.g.,-optimism, helplessness, self-efficacy), pain coping behaviors, and psychological well-being. Resilient coping, as assessed by the BRCS, also buffers the effects of high levels of arthritis-related and non-arthritis-related stressors on depressive symptoms. The sensitivity of the BRCS to changes associated with a cognitive-behavioral intervention is also demonstrated. The BCRS may be useful for identifying individuals in need of interventions designed to enhance resilient coping skills. {\textcopyright} 2004 Sage Publications.},
author = {Sinclair, Vaughn G. and Wallston, Kenneth A.},
doi = {10.1177/1073191103258144},
issn = {10731911},
journal = {Assessment},
keywords = {Coping,Rating scales,Resilience,Rheumatoid arthritis,Stress reactions},
month = {jul},
number = {1},
pages = {94--101},
pmid = {14994958},
publisher = {SAGE Publications},
title = {{The development and psychometric evaluation of the Brief Resilient Coping Scale}},
url = {https://journals.sagepub.com/doi/10.1177/1073191103258144},
volume = {11},
year = {2004}
}
@article{Baker2008,
abstract = {Will people report both posttraumatic growth and depreciation following a highly stressful event? Using the Posttraumatic Growth Inventory as the measure of growth, two studies compared responses t...},
author = {Baker, Jennifer M. and Kelly, Caroline and Calhoun, Lawrence G. and Cann, Arnie and Tedeschi, Richard G.},
doi = {10.1080/15325020802171367},
issn = {15325024},
journal = {http://dx.doi.org/10.1080/15325020802171367},
month = {sep},
number = {5},
pages = {450--465},
publisher = { Taylor & Francis Group },
title = {{An Examination of Posttraumatic Growth and Posttraumatic Depreciation: Two Exploratory Studies}},
url = {https://www.tandfonline.com/doi/abs/10.1080/15325020802171367},
volume = {13},
year = {2008}
}
@article{Schmidt2006,
abstract = {Background: Survey research including multiple health indicators requires brief indices for use in cross-cultural studies, which have, however, rarely been tested in terms of their psychometric quality. Recently, the EUROHIS-QOL 8-item index was developed as an adaptation of the WHOQOL-100 and the WHOQOL-BREF. The aim of the current study was to test the psychometric properties of the EUROHIS-QOL 8-item index. Methods: In a survey on 4849 European adults, the EUROHIS-QOL 8-item index was assessed across 10 countries, with equal samples adjusted for selected sociodemographic data. Participants were also investigated with a chronic condition checklist, measures on general health perception, mental health, health-care utilization and social support. Results: Findings indicated good internal consistencies across a range of countries, showing acceptable convergent validity with physical and mental health measures, and the measure discriminates well between individuals that report having a longstanding condition and healthy individuals across all countries. Differential item functioning was less frequently observed in those countries that were geographically and culturally closer to the UK, but acceptable across all countries. A universal one-factor structure with a good fit in structural equation modelling analyses (SEM) was identified with, however, limitations in model fit for specific countires. Conclusions: The short EUROHIS-QOL 8-item index showed good cross-cultural field study performance and a satisfactory convergent and discriminant validity, and can therefore be recommended for use in public health research. In future studies the measure should also be tested in multinational clinical studies, particularly in order to test its sensitivity. {\textcopyright} The Author 2005. Published by Oxford University Press on behalf of the European Public Health Association. All rights reserved.},
author = {Schmidt, Silke and M{\"{u}}hlan, Holger and Power, Mick},
doi = {10.1093/EURPUB/CKI155},
issn = {1101-1262},
journal = {European Journal of Public Health},
keywords = {Cross-cultural,EUROHIS,Health indicator,Quality of life,Short version},
month = {aug},
number = {4},
pages = {420--428},
pmid = {16141303},
publisher = {Oxford Academic},
title = {{The EUROHIS-QOL 8-item index: psychometric results of a cross-cultural field study}},
url = {https://academic.oup.com/eurpub/article/16/4/420/644306},
volume = {16},
year = {2006}
}
@misc{Henry2022,
abstract = {A toolbox for working with base types, core R features like the condition system, and core 'Tidyverse' features like tidy evaluation.},
author = {Henry, Lionel and Wickham, Hadley.},
title = {{rlang: Functions for Base Types and Core R and 'Tidyverse' Features}},
url = {https://cran.r-project.org/web/packages/rlang/index.html},
year = {2022}
}
@article{Hartigan1979,
abstract = {The K-means clustering algorithm is described indetail by Hartigan(1975). An efficient version of the algorithm is presented here.\nThe aim of the K-means algorithm is to divide M points in N dimensions into K clusters so that the within-cluster sum of squares is minimized. It is not practical to require that the solution has minimal sum of squares against all partitions except when M,N are small and K = 2. We seek instead "local" optima, solution such that no movement of a point from one cluster to another will reduce the within cluster sum of squares.},
author = {Hartigan, J. A. and Wong, M. A.},
doi = {10.2307/2346830},
issn = {00359254},
journal = {Applied Statistics},
number = {1},
pages = {100},
publisher = {JSTOR},
title = {{Algorithm AS 136: A K-Means Clustering Algorithm}},
volume = {28},
year = {1979}
}
@misc{Barnier2022,
abstract = {HTML formats and templates for 'rmarkdown' documents, with some extra features such as automatic table of contents, lightboxed figures, dynamic crosstab helper.},
author = {Barnier, Julien},
title = {{rmdformats: HTML Output Formats and Templates for 'rmarkdown' Documents}},
url = {https://cran.r-project.org/web/packages/rmdformats/index.html},
year = {2022}
}
@article{Lange2004,
abstract = {Data clustering describes a set of frequently employed techniques in exploratory data analysis to extract "natural" group structure in data. Such groupings need to be validated to separate the signal in the data from spurious structure. In this context, finding an appropriate number of clusters is a particularly important model selection question. We introduce a measure of cluster stability to assess the validity of a cluster model. This stability measure quantifies the reproducibility of clustering solutions on a second sample, and it can be interpreted as a classification risk with regard to class labels produced by a clustering algorithm. The preferred number of clusters is determined by minimizing this classification risk as a function of the number of clusters. Convincing results are achieved on simulated as well as gene expression data sets. Comparisons to other methods demonstrate the competitive performance of our method and its suitability as a general validation tool for clustering solutions in real-world problems.},
author = {Lange, Tilman and Roth, Volker and Braun, Mikio L. and Buhmann, Joachim M.},
doi = {10.1162/089976604773717621},
issn = {08997667},
journal = {Neural Computation},
month = {jun},
number = {6},
pages = {1299--1323},
pmid = {15130251},
publisher = {MIT Press},
title = {{Stability-based validation of clustering solutions}},
volume = {16},
year = {2004}
}
@misc{Xie2022,
abstract = {Provides a general-purpose tool for dynamic report generation in R using Literate Programming techniques.},
author = {Xie, Yihui},
title = {{knitr: A General-Purpose Package for Dynamic Report Generation in R}},
url = {https://cran.r-project.org/web/packages/knitr/index.html},
year = {2022}
}
@article{Maercker2005,
author = {Maercker, Andreas and Bromberger, Florentine},
journal = {Trierer Psychologische Berichte},
title = {{Checklisten und Fragebogen zur Erfassung traumatischer Ereignisse in deutscher Sprache}},
volume = {32},
year = {2005}
}
@article{Revelle2022,
abstract = {Description A number of routines for personality, psychometrics and experimental psychology. Functions are primarily for scale construction using factor analysis, cluster analysis and reliability analysis, although others provide basic descriptive statistics. Functions for ...},
author = {Revelle, William},
journal = {R Package},
pages = {1--358},
title = {{Package 'psych' - Procedures for Psychological, Psychometric and Personality Research}},
url = {https://cran.r-project.org/web/packages/psych/index.html http://personality-project.org/r/psych-manual.pdf},
year = {2015}
}
@article{Field2005,
abstract = {Kendall's Coefficient of Concordance, W, is a measure of the agreement between several judges who have rank ordered several entities. It represents the ratio of the variability of the total ranks for the ranked entities to the maximum possible variability of the total ranks; a small ratio implies disagreement between judges.},
author = {Field, Andy P.},
doi = {10.1002/0470013192.BSA327},
journal = {Encyclopedia of Statistics in Behavioral Science},
keywords = {agreement,correlation,ranked data},
month = {oct},
publisher = {John Wiley & Sons, Ltd},
title = {{Kendall's Coefficient of Concordance}},
url = {https://onlinelibrary.wiley.com/doi/full/10.1002/0470013192.bsa327 https://onlinelibrary.wiley.com/doi/abs/10.1002/0470013192.bsa327 https://onlinelibrary.wiley.com/doi/10.1002/0470013192.bsa327},
year = {2005}
}
@article{Wehrens2018,
abstract = {Self-organizing maps (SOMs) are popular tools for grouping and visualizing data in many areas of science. This paper describes recent changes in package kohonen, implementing several different forms of SOMs. These changes are primarily focused on making the package more useable for large data sets. Memory consumption has decreased dramatically, amongst others, by replacing the old interface to the underlying compiled code by a new one relying on Rcpp. The batch SOM algorithm for training has been added in both sequential and parallel forms. A final important extension of the package's repertoire is the possibility to define and use data-dependent distance functions, extremely useful in cases where standard distances like the Euclidean distance are not appropriate. Several examples of possible applications are presented.},
author = {Wehrens, Ron and Kruisselbrink, Johannes},
doi = {10.18637/jss.v087.i07},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {Distance functions,Parallellization, R.,Self-organizing maps},
month = {oct},
number = {7},
pages = {1--18},
publisher = {American Statistical Association},
title = {{Flexible self-organizing maps in kohonen 3.0}},
url = {https://www.jstatsoft.org/index.php/jss/article/view/v087i07/v87i07.pdf https://www.jstatsoft.org/index.php/jss/article/view/v087i07},
volume = {87},
year = {2018}
}
@article{Ribeiro2013,
abstract = {Background Violence and other traumatic events, as well as psychiatric disorders are frequent in developing countries, but there are few population studies to show the actual impact of traumatic events in the psychiatric morbidity in low and middle-income countries (LMIC).  Aims To study the relationship between traumatic events and prevalence of mental disorders in S{\~{a}}o Paulo and Rio de Janeiro, Brazil.  Methods Cross-sectional survey carried out in 2007–2008 with a probabilistic representative sample of 15- to 75-year-old residents in Sao Paulo and Rio de Janeiro, Brazil, using the Composite International Diagnostic Interview.  Results The sample comprised 3744 interviews. Nearly 90% of participants faced lifetime traumatic events. Lifetime prevalence of any disorders was 44% in Sao Paulo and 42.1% in Rio de Janeiro. One-year estimates were 32.5% and 31.2%. One-year prevalence of traumatic events was higher in Rio de Janeiro than Sao Paulo (35.1 vs. 21.7; p<0.001). Participants from Rio de Janeiro were less likely to have alcohol dependence (OR = 0.55; p = 0.027), depression (OR = 0.6; p = 0.006) generalized anxiety (OR = 0.59; p = 0.021) and post-traumatic stress disorder (OR = 0.62; p = 0.027). Traumatic events correlated with all diagnoses – e.g. assaultive violence with alcohol dependence (OR = 5.7; p<0.001) and with depression (OR = 1.7; p = 0.001).  Conclusion Our findings show that psychiatric disorders and traumatic events, especially violence, are extremely common in Sao Paulo and Rio de Janeiro, supporting the idea that neuropsychiatric disorders and external causes have become a major public health priority, as they are amongst the leading causes of burden of disease in low and middle-income countries. The comparison between the two cities regarding patterns of violence and psychiatric morbidity suggests that environmental factors may buffer the negative impacts of traumatic events. Identifying such factors might guide the implementation of interventions to improve mental health and quality of life in LMIC urban centers.},
author = {Ribeiro, Wagner Silva and Mari, Jair de Jesus and Quintana, Maria In{\^{e}}s and Dewey, Michael E. and Evans-Lacko, Sara and Vilete, Liliane Maria Pereira and Figueira, Ivan and Bressan, Rodrigo Affonseca and de Mello, Marcelo Feij{\'{o}} and Prince, Martin and Ferri, Cleusa P. and Coutinho, Evandro Silva Freire and Andreoli, S{\'{e}}rgio Baxter},
doi = {10.1371/JOURNAL.PONE.0063545},
issn = {1932-6203},
journal = {PLOS ONE},
keywords = {Alcoholism,Anxiety disorders,Brazil,Cities,Depression,Post-traumatic stress disorder,Traumatic injury,Urban areas},
month = {may},
number = {5},
pages = {e63545},
pmid = {23667636},
publisher = {Public Library of Science},
title = {{The Impact of Epidemic Violence on the Prevalence of Psychiatric Disorders in Sao Paulo and Rio de Janeiro, Brazil}},
url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0063545},
volume = {8},
year = {2013}
}
@inproceedings{Todorov2013,
abstract = {The main drawback of principal component analysis (PCA) especially for applications in high dimensions is that the extracted components are linear combinations of all input variables. To facilitate the interpretability of PCA various sparse methods have been proposed recently. However all these methods might suffer from the influence of outliers present in the data. An algorithm to compute sparse and robust PCA was recently proposed by Croux et al. We compare this method to standard (non-sparse) classical and robust PCA and several other sparse methods. The considered methods are illustrated on a real data example and compared in a simulation experiment. It is shown that the robust sparse method preserves the sparsity and at the same time provides protection against contamination. {\textcopyright} 2013 Springer-Verlag.},
author = {Todorov, Valentin and Filzmoser, Peter},
booktitle = {Advances in Intelligent Systems and Computing},
doi = {10.1007/978-3-642-33042-1_31},
isbn = {9783642330414},
issn = {21945357},
keywords = {Principcal component analysis,robust statistics},
pages = {283--291},
publisher = {Springer Verlag},
title = {{Comparing classical and robust sparse PCA}},
url = {https://link.springer.com/chapter/10.1007/978-3-642-33042-1_31},
volume = {190 AISC},
year = {2013}
}
@article{Cohen1983,
author = {Cohen, S. and Kamarck, T. and Mermelstein, R.},
doi = {10.2307/2136404},
issn = {00221465},
journal = {Journal of health and social behavior},
number = {4},
pages = {385--396},
pmid = {6668417},
title = {{A global measure of perceived stress.}},
volume = {24},
year = {1983}
}
@article{Drost2018,
abstract = {Comparison is a fundamental method of scientific research leading to insights about the processes that generate similarity or dissimilarity. In statistical terms comparisons between probability functions are performed to infer connections, correlations, or relationships between objects or samples (Cha 2007). Most quantification methods rely on distance or similarity measures, but the right choice for each individual application is not always clear and sometimes poorly explored. The reason for this is partly that diverse measures are either implemented in different R packages with very different notations or are not implemented at all. Thus, a comprehensive framework implementing the most common similarity and distance measures using a uniform notation is still missing. The R (R Core Team 2018) package Philentropy aims to fill this gap by implementing forty-six fundamental distance and similarity measures (Cha 2007) for comparing probability functions. These comparisons between probability functions have their foundations in a broad range of scientific disciplines from mathematics to ecology. The aim of this package is to provide a comprehensive and computationally optimized base framework for clustering, classification, statistical inference, goodness-of-fit, non-parametric statistics, information theory, and machine learning tasks that are based on comparing univariate or multivari-ate probability functions. All functions are written in C++ and are integrated into the R package using the Rcpp Application Programming Interface (API) (Eddelbuettel 2013). Together, this framework allows building new similarity or distance based (statistical) models and algorithms in R which are computationally efficient and scalable. The comprehensive availability of diverse metrics and measures furthermore enables a systematic assessment of choosing the most optimal similarity or distance measure for individual applications in diverse scientific disciplines. The following probability distance/similarity and information theory measures are implemented in Philentropy. Distance and Similarity Measures L p Minkowski Family • Euclidean : d = √ ∑ N i=1 |P i − Q i | 2) • Manhattan : d = ∑ N i=1 |P i − Q i | • Minkowski : d = (∑ N i=1 |P i − Q i | p) 1/p • Chebyshev : d = max|P i − Q i | L 1 Family • Sorensen : d = ∑ N i=1 |Pi−Qi| ∑ N i=1 (Pi+Qi) Drost, (2018). Philentropy: Information Theory and Distance Quantification with R. Journal of Open Source Software, 3(26), 765.},
author = {Drost, Hajk-Georg},
doi = {10.21105/joss.00765},
file = {:C\:/Users/piotr/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Drost - 2018 - Philentropy Information Theory and Distance Quantification with R.pdf:pdf},
issn = {2475-9066},
journal = {Journal of Open Source Software},
month = {jun},
number = {26},
pages = {765},
publisher = {The Open Journal},
title = {{Philentropy: Information Theory and Distance Quantification with R}},
url = {https://doi.org/10.21105/joss.00765},
volume = {3},
year = {2018}
}
@book{Wickham2016,
address = {New York},
author = {Wickham, Hadley.},
edition = {1},
isbn = {978-3-319-24277-4},
publisher = {Springer-Verlag},
title = {{ggplot2: Elegant Graphics for Data Analysis}},
url = {https://ggplot2.tidyverse.org},
year = {2016}
}
@misc{PTSD,
author = {for PTSD, National Center},
title = {{Using the PTSD Checklist for DSM-5 (PCL-5) www.ptsd.va.gov}},
url = {http://www.ptsd.va.gov/professional/assessment/adult-sr/ptsd-checklist.asp},
urldate = {2022-09-26}
}
@article{Leppert2008,
author = {Leppert, K and Koch, B and Br{\"{a}}hler, E and Und, B Strau{\ss} - Klinische Diagnostik and 2008, Undefined},
journal = {Klinische Diagnostik und Evaluation},
pages = {226--243},
title = {{Die Resilienzskala (RS)–{\"{U}}berpr{\"{u}}fung der Langform RS-25 und einer Kurzform RS-13}},
url = {https://www.academia.edu/download/44388154/A_406.pdf},
volume = {1},
year = {2008}
}
@article{Bovin2016,
abstract = {This study examined the psychometric properties of the posttraumatic stress disorder (PTSD) Checklist for Diagnostic and Statistical Manual of Mental Disorders-Fifth Edition (PCL-5; Weathers, Litz, et al., 2013b) in 2 independent samples of veterans receiving care at a Veterans Affairs Medical Center (N = 468). A subsample of these participants (n = 140) was used to define a valid diagnostic cutoff score for the instrument using the Clinician-Administered PTSD Scale for DSM-5 (CAPS-5; Weathers, Blake, et al., 2013) as the reference standard. The PCL-5 test scores demonstrated good internal consistency (a =. 96), test-retest reliability (r =. 84), and convergent and discriminant validity. Consistent with previous studies (Armour et al., 2015; Liu et al., 2014), confirmatory factor analysis revealed that the data were best explained by a 6-factor anhedonia model and a 7-factor hybrid model. Signal detection analyses using the CAPS-5 revealed that PCL-5 scores of 31 to 33 were optimally efficient for diagnosing PTSD (k(.5) =. 58). Overall, the findings suggest that the PCL-5 is a psychometrically sound instrument that can be used effectively with veterans. Further, by determining a valid cutoff score using the CAPS-5, the PCL-5 can now be used to identify veterans with probable PTSD. However, findings also suggest the need for research to evaluate cluster structure of DSM-5.},
author = {Bovin, Michelle J. and Marx, Brian P. and Weathers, Frank W. and Gallagher, Matthew W. and Rodriguez, Paola and Schnurr, Paula P. and Keane, Terence M.},
doi = {10.1037/PAS0000254},
issn = {1939-134X},
journal = {Psychological assessment},
keywords = {80 and over,Adolescent,Adult,Aged,Brian P Marx,Checklist,Diagnostic and Statistical Manual of Mental Disord,Female,Humans,MEDLINE,Male,Michelle J Bovin,Middle Aged,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Post-Traumatic / diagnosis*,Psychiatric Status Rating Scales*,Psychometrics,PubMed Abstract,Reproducibility of Results,Stress Disorders,Terence M Keane,United States,Veterans Health*,Young Adult,doi:10.1037/pas0000254,pmid:26653052},
month = {nov},
number = {11},
pages = {1379--1391},
pmid = {26653052},
publisher = {Psychol Assess},
title = {{Psychometric properties of the PTSD Checklist for Diagnostic and Statistical Manual of Mental Disorders-Fifth Edition (PCL-5) in veterans}},
url = {https://pubmed.ncbi.nlm.nih.gov/26653052/},
volume = {28},
year = {2016}
}
