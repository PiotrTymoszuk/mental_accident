@misc{Henry2022,
abstract = {A toolbox for working with base types, core R features like the condition system, and core 'Tidyverse' features like tidy evaluation.},
author = {Henry, Lionel and Wickham, Hadley.},
title = {{rlang: Functions for Base Types and Core R and 'Tidyverse' Features}},
url = {https://cran.r-project.org/web/packages/rlang/index.html},
year = {2022}
}
@article{Wickham2019,
abstract = {At a high level, the tidyverse is a language for solving data science challenges with R code. Its primary goal is to facilitate a conversation between a human and a computer about data. Less abstractly, the tidyverse is a collection of R packages that share a high-level design philosophy and low-level grammar and data structures, so that learning one package makes it easier to learn the next. The tidyverse encompasses the repeated tasks at the heart of every data science project: data import, tidying, manipulation, visualisation, and programming. We expect that almost every project will use multiple domain-specific packages outside of the tidyverse: our goal is to provide tooling for the most common challenges; not to solve every possible problem. Notably, the tidyverse doesn't include tools for statistical modelling or communication. These toolkits are critical for data science, but are so large that they merit separate treatment. The tidyverse package allows users to install all tidyverse packages with a single command. There are a number of projects that are similar in scope to the tidyverse. The closest is perhaps Bioconductor (Gentleman et al., 2004; Huber et al., 2015), which provides an ecosystem of packages that support the analysis of high-throughput genomic data.},
author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and McGowan, Lucy and Fran{\c{c}}ois, Romain and Grolemund, Garrett and Hayes, Alex and Henry, Lionel and Hester, Jim and Kuhn, Max and Pedersen, Thomas and Miller, Evan and Bache, Stephan and M{\"{u}}ller, Kirill and Ooms, Jeroen and Robinson, David and Seidel, Dana and Spinu, Vitalie and Takahashi, Kohske and Vaughan, Davis and Wilke, Claus and Woo, Kara and Yutani, Hiroaki},
doi = {10.21105/joss.01686},
file = {:C\:/Users/piotr/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wickham et al. - 2019 - Welcome to the Tidyverse.pdf:pdf},
issn = {2475-9066},
journal = {Journal of Open Source Software},
month = {nov},
number = {43},
pages = {1686},
publisher = {The Open Journal},
title = {{Welcome to the Tidyverse}},
volume = {4},
year = {2019}
}
@misc{Gohel2022,
abstract = {Create pretty tables for 'HTML', 'PDF', 'Microsoft Word' and 'Microsoft PowerPoint' documents from 'R Markdown'. Functions are provided to let users create tables, modify and format their content. It also extends package 'officer' that does not contain any feature for customized tabular reporting.},
author = {Gohel, David},
title = {{flextable: Functions for Tabular Reporting}},
url = {https://cran.r-project.org/web/packages/flextable/index.html},
year = {2022}
}
@misc{Allaire2022,
abstract = {Convert R Markdown documents into a variety of formats.},
author = {Allaire, JJ and Xie, Yihui and McPherson, Jonathan and Luraschi, Javier and Ushey, Kevin and Atkins, Aron and Wickham, Hadley and Cheng, Joe},
title = {{rmarkdown: Dynamic Documents for R}},
url = {https://cran.r-project.org/web/packages/rmarkdown/index.html},
year = {2022}
}
@misc{Xie2022,
abstract = {Provides a general-purpose tool for dynamic report generation in R using Literate Programming techniques.},
author = {Xie, Yihui},
title = {{knitr: A General-Purpose Package for Dynamic Report Generation in R}},
url = {https://cran.r-project.org/web/packages/knitr/index.html},
year = {2022}
}
@misc{Kassambara2021,
author = {Kassambara, Alboukadel},
title = {{rstatix: Pipe-Friendly Framework for Basic Statistical Tests}},
url = {https://cran.r-project.org/package=rstatix},
year = {2021}
}
@article{Benjamini1995,
abstract = {The common approach to the multiplicity problem calls for controlling the familywise error rate (FWER). This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses- the false discovery rate. This error rate is equivalent to the FWER when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the FWER is desired, there is potential for a gain in power. A simple sequential Bonferronitype procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.},
author = {Benjamini, Yoav and Hochberg, Yosef},
doi = {10.1111/j.2517-6161.1995.tb02031.x},
issn = {0035-9246},
journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
keywords = {bonferroni‐type procedures,familywise error rate,multiple‐comparison procedures,p‐values},
month = {jan},
number = {1},
pages = {289--300},
publisher = {Wiley},
title = {{Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing}},
volume = {57},
year = {1995}
}
@book{Xie2016,
abstract = {bookdown: Authoring Books and Technical Documents with R Markdown presents a much easier way to write books and technical publications than traditional tools such as LaTeX and Word. The bookdown package inherits the simplicity of syntax and flexibility for data analysis from R Markdown, and extends R Markdown for technical writing, so that you can make better use of document elements such as figures, tables, equations, theorems, citations, and references. Similar to LaTeX, you can number and cross-reference these elements with bookdown. Your document can even include live examples so readers can interact with them while reading the book. The book can be rendered to multiple output formats, including LaTeX/PDF, HTML, EPUB, and Word, thus making it easy to put your documents online. The style and theme of these output formats can be customized. We used books and R primarily for examples in this book, but bookdown is not only for books or R. Most features introduced in this book also apply to other types of publications: journal papers, reports, dissertations, course handouts, study notes, and even novels. You do not have to use R, either. Other choices of computing languages include Python, C, C plus plus, SQL, Bash, Stan, JavaScript, and so on, although R is best supported. You can also leave out computing, for example, to write a fiction. This book itself is an example of publishing with bookdown and R Markdown, and its source is fully available on GitHub.},
author = {Xie, Yihui},
booktitle = {Bookdown: Authoring Books and Technical Documents with R Markdown},
doi = {10.1201/9781315204963},
isbn = {9781351792608},
pages = {1--113},
title = {{Bookdown: Authoring books and technical documents with R Markdown}},
year = {2016}
}
@book{Wilke2019,
abstract = {First edition. Intro; Copyright; Table of Contents; Preface; Thoughts on Graphing Software and Figure-Preparation Pipelines; Conventions Used in This Book; Using Code Examples; O'Reilly Online Learning; How to Contact Us; Acknowledgments; Chapter 1. Introduction; Ugly, Bad, and Wrong Figures; Part I. From Data to Visualization; Chapter 2. Visualizing Data: Mapping Data onto Aesthetics; Aesthetics and Types of Data; Scales Map Data Values onto Aesthetics; Chapter 3. Coordinate Systems and Axes; Cartesian Coordinates; Nonlinear Axes; Coordinate Systems with Curved Axes; Chapter 4. Color Scales Color as a Tool to DistinguishColor to Represent Data Values; Color as a Tool to Highlight; Chapter 5. Directory of Visualizations; Amounts; Distributions; Proportions; x-y relationships; Geospatial Data; Uncertainty; Chapter 6. Visualizing Amounts; Bar Plots; Grouped and Stacked Bars; Dot Plots and Heatmaps; Chapter 7. Visualizing Distributions: Histograms and Density Plots; Visualizing a Single Distribution; Visualizing Multiple Distributions at the Same Time; Chapter 8. Visualizing Distributions: Empirical Cumulative Distribution Functions and Q-Q Plots Empirical Cumulative Distribution FunctionsHighly Skewed Distributions; Quantile-Quantile Plots; Chapter 9. Visualizing Many Distributions at Once; Visualizing Distributions Along the Vertical Axis; Visualizing Distributions Along the Horizontal Axis; Chapter 10. Visualizing Proportions; A Case for Pie Charts; A Case for Side-by-Side Bars; A Case for Stacked Bars and Stacked Densities; Visualizing Proportions Separately as Parts of the Total; Chapter 11. Visualizing Nested Proportions; Nested Proportions Gone Wrong; Mosaic Plots and Treemaps; Nested Pies; Parallel Sets Chapter 12. Visualizing Associations Among Two or More Quantitative VariablesScatterplots; Correlograms; Dimension Reduction; Paired Data; Chapter 13. Visualizing Time Series and Other Functions of an Independent Variable; Individual Time Series; Multiple Time Series and Dose-Response Curves; Time Series of Two or More Response Variables; Chapter 14. Visualizing Trends; Smoothing; Showing Trends with a Defined Functional Form; Detrending and Time-Series Decomposition; Chapter 15. Visualizing Geospatial Data; Projections; Layers; Choropleth Mapping; Cartograms Chapter 16. Visualizing UncertaintyFraming Probabilities as Frequencies; Visualizing the Uncertainty of Point Estimates; Visualizing the Uncertainty of Curve Fits; Hypothetical Outcome Plots; Part II. Principles of Figure Design; Chapter 17. The Principle of Proportional Ink; Visualizations Along Linear Axes; Visualizations Along Logarithmic Axes; Direct Area Visualizations; Chapter 18. Handling Overlapping Points; Partial Transparency and Jittering; 2D Histograms; Contour Lines; Chapter 19. Common Pitfalls of Color Use; Encoding Too Much or Irrelevant Information},
address = {Sebastopol},
author = {Wilke, Claus O},
booktitle = {O'Reilly Media},
edition = {1},
isbn = {1492031089},
pages = {389},
publisher = {O'Reilly Media},
title = {{Fundamentals of Data Visualization: A Primer on Making Informative and Compelling Figures}},
year = {2019}
}
@book{Wickham2016,
address = {New York},
author = {Wickham, Hadley.},
edition = {1},
isbn = {978-3-319-24277-4},
publisher = {Springer-Verlag},
title = {{ggplot2: Elegant Graphics for Data Analysis}},
url = {https://ggplot2.tidyverse.org},
year = {2016}
}
@inproceedings{Todorov2013,
abstract = {The main drawback of principal component analysis (PCA) especially for applications in high dimensions is that the extracted components are linear combinations of all input variables. To facilitate the interpretability of PCA various sparse methods have been proposed recently. However all these methods might suffer from the influence of outliers present in the data. An algorithm to compute sparse and robust PCA was recently proposed by Croux et al. We compare this method to standard (non-sparse) classical and robust PCA and several other sparse methods. The considered methods are illustrated on a real data example and compared in a simulation experiment. It is shown that the robust sparse method preserves the sparsity and at the same time provides protection against contamination. {\textcopyright} 2013 Springer-Verlag.},
author = {Todorov, Valentin and Filzmoser, Peter},
booktitle = {Advances in Intelligent Systems and Computing},
doi = {10.1007/978-3-642-33042-1_31},
isbn = {9783642330414},
issn = {21945357},
keywords = {Principcal component analysis,robust statistics},
pages = {283--291},
publisher = {Springer Verlag},
title = {{Comparing classical and robust sparse PCA}},
url = {https://link.springer.com/chapter/10.1007/978-3-642-33042-1_31},
volume = {190 AISC},
year = {2013}
}
@article{Croux2007,
abstract = {The results of a standard principal component analysis (PCA) can be affected by the presence of outliers. Hence robust alternatives to PCA are needed. One of the most appealing robust methods for principal component analysis uses the Projection-Pursuit principle. Here, one projects the data on a lower-dimensional space such that a robust measure of variance of the projected data will be maximized. The Projection-Pursuit-based method for principal component analysis has recently been introduced in the field of chemometrics, where the number of variables is typically large. In this paper, it is shown that the currently available algorithm for robust Projection-Pursuit PCA performs poor in the presence of many variables. A new algorithm is proposed that is more suitable for the analysis of chemical data. Its performance is studied by means of simulation experiments and illustrated on some real data sets. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Croux, C. and Filzmoser, P. and Oliveira, M. R.},
doi = {10.1016/j.chemolab.2007.01.004},
issn = {01697439},
journal = {Chemometrics and Intelligent Laboratory Systems},
keywords = {Multivariate statistics,Numerical precision,Optimization,Outliers,Robustness,Scale estimators},
month = {jun},
number = {2},
pages = {218--225},
publisher = {Elsevier},
title = {{Algorithms for Projection-Pursuit robust principal component analysis}},
volume = {87},
year = {2007}
}
@misc{Barnier2022,
abstract = {HTML formats and templates for 'rmarkdown' documents, with some extra features such as automatic table of contents, lightboxed figures, dynamic crosstab helper.},
author = {Barnier, Julien},
title = {{rmdformats: HTML Output Formats and Templates for 'rmarkdown' Documents}},
url = {https://cran.r-project.org/web/packages/rmdformats/index.html},
year = {2022}
}
@article{McInnes2018,
abstract = {UMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension reduction. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic topology. The result is a practical scalable algorithm that applies to real world data. The UMAP algorithm is competitive with t-SNE for visualization quality, and arguably preserves more of the global structure with superior run time performance. Furthermore, UMAP has no computational restrictions on embedding dimension, making it viable as a general purpose dimension reduction technique for machine learning.},
archivePrefix = {arXiv},
arxivId = {1802.03426},
author = {McInnes, Leland and Healy, John and Melville, James},
eprint = {1802.03426},
month = {feb},
title = {{UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction}},
url = {https://arxiv.org/abs/1802.03426v3 http://arxiv.org/abs/1802.03426},
year = {2018}
}
@article{Maercker2005,
author = {Maercker, Andreas and Bromberger, Florentine},
journal = {Trierer Psychologische Berichte},
title = {{Checklisten und Fragebogen zur Erfassung traumatischer Ereignisse in deutscher Sprache}},
volume = {32},
year = {2005}
}
@article{Bovin2016,
abstract = {This study examined the psychometric properties of the posttraumatic stress disorder (PTSD) Checklist for Diagnostic and Statistical Manual of Mental Disorders-Fifth Edition (PCL-5; Weathers, Litz, et al., 2013b) in 2 independent samples of veterans receiving care at a Veterans Affairs Medical Center (N = 468). A subsample of these participants (n = 140) was used to define a valid diagnostic cutoff score for the instrument using the Clinician-Administered PTSD Scale for DSM-5 (CAPS-5; Weathers, Blake, et al., 2013) as the reference standard. The PCL-5 test scores demonstrated good internal consistency (a =. 96), test-retest reliability (r =. 84), and convergent and discriminant validity. Consistent with previous studies (Armour et al., 2015; Liu et al., 2014), confirmatory factor analysis revealed that the data were best explained by a 6-factor anhedonia model and a 7-factor hybrid model. Signal detection analyses using the CAPS-5 revealed that PCL-5 scores of 31 to 33 were optimally efficient for diagnosing PTSD (k(.5) =. 58). Overall, the findings suggest that the PCL-5 is a psychometrically sound instrument that can be used effectively with veterans. Further, by determining a valid cutoff score using the CAPS-5, the PCL-5 can now be used to identify veterans with probable PTSD. However, findings also suggest the need for research to evaluate cluster structure of DSM-5.},
author = {Bovin, Michelle J. and Marx, Brian P. and Weathers, Frank W. and Gallagher, Matthew W. and Rodriguez, Paola and Schnurr, Paula P. and Keane, Terence M.},
doi = {10.1037/PAS0000254},
issn = {1939-134X},
journal = {Psychological assessment},
keywords = {80 and over,Adolescent,Adult,Aged,Brian P Marx,Checklist,Diagnostic and Statistical Manual of Mental Disord,Female,Humans,MEDLINE,Male,Michelle J Bovin,Middle Aged,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Post-Traumatic / diagnosis*,Psychiatric Status Rating Scales*,Psychometrics,PubMed Abstract,Reproducibility of Results,Stress Disorders,Terence M Keane,United States,Veterans Health*,Young Adult,doi:10.1037/pas0000254,pmid:26653052},
month = {nov},
number = {11},
pages = {1379--1391},
pmid = {26653052},
publisher = {Psychol Assess},
title = {{Psychometric properties of the PTSD Checklist for Diagnostic and Statistical Manual of Mental Disorders-Fifth Edition (PCL-5) in veterans}},
url = {https://pubmed.ncbi.nlm.nih.gov/26653052/},
volume = {28},
year = {2016}
}
@article{Grafe2004,
abstract = {The aim of this study was to validate the German version of the "Patient Health Questionnaire (PHQ)". The PHQ has been developed to screen for mental disorders in primary care, using diagnostic criteria from the DSM-IV. Three hundred and fifty-seven medical outpatients and 171 psychosomatic outpatients completed the PHQ and the Structured Clinical Interview for DSM-IV (SCID), the latter serving as criterion standard. Acceptability of the PHQ as the screening instrument was investigated for physicians and patients. For the diagnosis of major depressive disorder, the PHQ showed excellent criterion validity (medical patients: sensitivity, 95%; specificity, 86%). Good operating characteristics were also found for the diagnosis of panic disorder. The use of the PHQ was well accepted by more than 90% of both physicians and patients. Overall, the PHQ is a valid, effective, and well accepted diagnostic tool for use in research and clinical practice. Its' application in primary care and other clinical settings might contribute to better diagnosis and treatment of mental disorders.},
author = {Gr{\"{a}}fe, Kerstin and Zipfel, Stephan and Herzog, Wolfgang and L{\"{o}}we, Bernd},
doi = {10.1026/0012-1924.50.4.171},
issn = {00121924},
journal = {Diagnostica},
keywords = {Mental disorders,Primary care,Psychosomatic medicine,Screening test,Validity},
month = {oct},
number = {4},
pages = {171--181},
publisher = { Hogrefe Verlag G{\"{o}}ttingen },
title = {{Screening psychischer st{\"{o}}rungen mit dem "Gesundheitsfragebogen f{\"{u}}r Patienten (PHQ-D)". Ergebnisse der Deutschen validierungsstudie}},
url = {https://econtent.hogrefe.com/doi/abs/10.1026/0012-1924.50.4.171},
volume = {50},
year = {2004}
}
@inproceedings{Schubert2019,
abstract = {Clustering non-Euclidean data is difficult, and one of the most used algorithms besides hierarchical clustering is the popular algorithm Partitioning Around Medoids (PAM), also simply referred to as k-medoids. In Euclidean geometry the mean—as used in k-means—is a good estimator for the cluster center, but this does not exist for arbitrary dissimilarities. PAM uses the medoid instead, the object with the smallest dissimilarity to all others in the cluster. This notion of centrality can be used with any (dis-)similarity, and thus is of high relevance to many domains and applications. A key issue with PAM is its high run time cost. We propose modifications to the PAM algorithm that achieve an O(k)-fold speedup in the second (“SWAP”) phase of the algorithm, but will still find the same results as the original PAM algorithm. If we slightly relax the choice of swaps performed (while retaining comparable quality), we can further accelerate the algorithm by performing up to k swaps in each iteration. With the substantially faster SWAP, we can now explore faster intialization strategies. We also show how the CLARA and CLARANS algorithms benefit from the proposed modifications.},
archivePrefix = {arXiv},
arxivId = {1810.05691},
author = {Schubert, Erich and Rousseeuw, Peter J.},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-030-32047-8_16},
eprint = {1810.05691},
isbn = {9783030320461},
issn = {16113349},
keywords = {CLARA,CLARANS,Cluster analysis,PAM,k-Medoids},
month = {oct},
pages = {171--187},
publisher = {Springer},
title = {{Faster k-Medoids Clustering: Improving the PAM, CLARA, and CLARANS Algorithms}},
url = {https://link.springer.com/chapter/10.1007/978-3-030-32047-8_16},
volume = {11807 LNCS},
year = {2019}
}
@article{Cohen1983,
author = {Cohen, S. and Kamarck, T. and Mermelstein, R.},
doi = {10.2307/2136404},
issn = {00221465},
journal = {Journal of health and social behavior},
number = {4},
pages = {385--396},
pmid = {6668417},
title = {{A global measure of perceived stress.}},
volume = {24},
year = {1983}
}
@article{Sinclair2004,
abstract = {This article introduces the Brief Resilient Coping Scale (BRCS), a 4-item measure designed to capture tendencies to cope with stress in a highly adaptive manner. Two samples of individuals with rheumatoid arthritis (ns = 90 and 140) provide evidence for the reliability and validity of the BRCS. The BRCS has adequate internal consistency and test-re test reliability. Convergent validity of the scale is demonstrated by predictable correlations with measures of personal coping resources (e.g.,-optimism, helplessness, self-efficacy), pain coping behaviors, and psychological well-being. Resilient coping, as assessed by the BRCS, also buffers the effects of high levels of arthritis-related and non-arthritis-related stressors on depressive symptoms. The sensitivity of the BRCS to changes associated with a cognitive-behavioral intervention is also demonstrated. The BCRS may be useful for identifying individuals in need of interventions designed to enhance resilient coping skills. {\textcopyright} 2004 Sage Publications.},
author = {Sinclair, Vaughn G. and Wallston, Kenneth A.},
doi = {10.1177/1073191103258144},
issn = {10731911},
journal = {Assessment},
keywords = {Coping,Rating scales,Resilience,Rheumatoid arthritis,Stress reactions},
month = {jul},
number = {1},
pages = {94--101},
pmid = {14994958},
publisher = {SAGE Publications},
title = {{The development and psychometric evaluation of the Brief Resilient Coping Scale}},
url = {https://journals.sagepub.com/doi/10.1177/1073191103258144},
volume = {11},
year = {2004}
}
@article{Hartigan1979,
abstract = {The K-means clustering algorithm is described indetail by Hartigan(1975). An efficient version of the algorithm is presented here.\nThe aim of the K-means algorithm is to divide M points in N dimensions into K clusters so that the within-cluster sum of squares is minimized. It is not practical to require that the solution has minimal sum of squares against all partitions except when M,N are small and K = 2. We seek instead "local" optima, solution such that no movement of a point from one cluster to another will reduce the within cluster sum of squares.},
author = {Hartigan, J. A. and Wong, M. A.},
doi = {10.2307/2346830},
issn = {00359254},
journal = {Applied Statistics},
number = {1},
pages = {100},
publisher = {JSTOR},
title = {{Algorithm AS 136: A K-Means Clustering Algorithm}},
volume = {28},
year = {1979}
}
@article{Field2005,
abstract = {Kendall's Coefficient of Concordance, W, is a measure of the agreement between several judges who have rank ordered several entities. It represents the ratio of the variability of the total ranks for the ranked entities to the maximum possible variability of the total ranks; a small ratio implies disagreement between judges.},
author = {Field, Andy P.},
doi = {10.1002/0470013192.BSA327},
journal = {Encyclopedia of Statistics in Behavioral Science},
keywords = {agreement,correlation,ranked data},
month = {oct},
publisher = {John Wiley & Sons, Ltd},
title = {{Kendall's Coefficient of Concordance}},
url = {https://onlinelibrary.wiley.com/doi/full/10.1002/0470013192.bsa327 https://onlinelibrary.wiley.com/doi/abs/10.1002/0470013192.bsa327 https://onlinelibrary.wiley.com/doi/10.1002/0470013192.bsa327},
year = {2005}
}
@article{Manea2012,
abstract = {Background: The brief Patient Health Questionnaire (PHQ-9) is commonly used to screen for depression with 10 often recommended as the cut-off score. We summarized the psychometric properties of the PHQ-9 across a range of studies and cut-off scores to select the optimal cut-off for detecting depression. Methods: We searched Embase, MEDLINE and PsycINFO from 1999 to August 2010 for studies that reported the diagnostic accuracy of PHQ-9 to diagnose major depressive disorders. We calculated summary sensitivity, specificity, likelihood ratios and diagnostic odds ratios for detecting major depressive disorder at different cut-off scores and in different settings. We used random-effects bivariate meta-analysis at cut-off points between 7 and 15 to produce summary receiver operating characteristic curves. Results: We identified 18 validation studies (n = 7180) conducted in various clinical settings. Eleven studies provided details about the diagnostic properties of the questionnaire at more than one cut-off score (including 10), four studies reported a cut-off score of 10, and three studies reported cut-off scores other than 10. The pooled specificity results ranged from 0.73 (95% confidence interval [CI] 0.63-0.82) for a cut-off score of 7 to 0.96 (95% CI 0.94-0.97) for a cut-off score of 15. There was major variability in sensitivity for cut-off scores between 7 and 15. There were no substantial differences in the pooled sensitivity and specificity for a range of cut-off scores (8-11). Interpretation: The PHQ-9 was found to have acceptable diagnostic properties for detecting major depressive disorder for cut-off scores between 8 and 11. Authors of future validation studies should consistently report the outcomes for different cut-off scores. {\textcopyright} 2012 Canadian Medical Association or its licensors.},
author = {Manea, Laura and Gilbody, Simon and McMillan, Dean},
doi = {10.1503/CMAJ.110829/-/DC1},
issn = {14882329},
journal = {CMAJ},
month = {feb},
number = {3},
pages = {E191},
pmid = {22184363},
publisher = {Canadian Medical Association},
title = {{Optimal cut-off score for diagnosing depression with the Patient Health Questionnaire (PHQ-9): A meta-analysis}},
url = {/pmc/articles/PMC3281183/ /pmc/articles/PMC3281183/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3281183/},
volume = {184},
year = {2012}
}
@article{Baker2008,
abstract = {Will people report both posttraumatic growth and depreciation following a highly stressful event? Using the Posttraumatic Growth Inventory as the measure of growth, two studies compared responses t...},
author = {Baker, Jennifer M. and Kelly, Caroline and Calhoun, Lawrence G. and Cann, Arnie and Tedeschi, Richard G.},
doi = {10.1080/15325020802171367},
issn = {15325024},
journal = {http://dx.doi.org/10.1080/15325020802171367},
month = {sep},
number = {5},
pages = {450--465},
publisher = { Taylor & Francis Group },
title = {{An Examination of Posttraumatic Growth and Posttraumatic Depreciation: Two Exploratory Studies}},
url = {https://www.tandfonline.com/doi/abs/10.1080/15325020802171367},
volume = {13},
year = {2008}
}
@article{Kroenke2002,
abstract = {Objective: Somatization is prevalent in primary care and is associated with substantial functional impairment and healthcare utilization. However, instruments for identifying and monitoring somatic symptoms are few in number and not widely used. Therefore, we examined the validity of a brief measure of the severity of somatic symptoms. Methods: The Patient Health Questionnaire (PHQ) is a self-administered version of the PRIME-MD diagnostic instrument for common mental disorders. The PHQ-15 comprises 15 somatic symptoms from the PHQ, each symptom scored from 0 ("not bothered at all") to 2 ("bothered a lot"). The PHQ-15 was administered to 6000 patients in eight general internal medicine and family practice clinics and seven obstetrics-gynecology clinics. Outcomes included functional status as assessed by the 20-item Short-Form General Health Survey (SF-20), self-reported sick days and clinic visits, and symptom-related difficulty. Results: As PHQ-15 somatic symptom severity increased, there was a substantial stepwise decrement in functional status on all six SF-20 subscales. Also, symptom-related difficulty, sick days, and healthcare utilization increased. PHQ-15 scores of 5, 10, 15, represented cutoff points for low, medium, and high somatic symptom severity, respectively. Somatic and depressive symptom severity had differential effects on outcomes. Results were similar in the primary care and obstetrics-gynecology samples. Conclusions: The PHQ-15 is a brief, self-administered questionnaire that may be useful in screening for somatization and in monitoring somatic symptom severity in clinical practice and research.},
author = {Kroenke, Kurt and Spitzer, Robert L. and Williams, Janet B.W.},
doi = {10.1097/00006842-200203000-00008},
issn = {0033-3174},
journal = {Psychosomatic medicine},
keywords = {Adult,Aged,Depression / diagnosis,Depression / psychology,Diagnosis,Differential,Family Practice,Female,Humans,Internal Medicine,Janet B W Williams,Kurt Kroenke,MEDLINE,Male,Middle Aged,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Non-U.S. Gov't,Patient Care Team,Personality Inventory / statistics & numerical dat,Pregnancy,Psychometrics,PubMed Abstract,Reproducibility of Results,Research Support,Robert L Spitzer,Somatoform Disorders / diagnosis*,Somatoform Disorders / psychology,doi:10.1097/00006842-200203000-00008,pmid:11914441},
number = {2},
pages = {258--266},
pmid = {11914441},
publisher = {Psychosom Med},
title = {{The PHQ-15: validity of a new measure for evaluating the severity of somatic symptoms}},
url = {https://pubmed.ncbi.nlm.nih.gov/11914441/},
volume = {64},
year = {2002}
}
@techreport{Lowe2002,
author = {L{\"{o}}we, Bernd and Spitzer, Robert L and Zipfel, Stephan and Herzog, Wolfgang},
file = {:C\:/Users/piotr/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/L{\"{o}}we et al. - 2002 - Auflage Manual 17.07.pdf:pdf},
pages = {44--45},
title = {{Auflage Manual 17.07}},
volume = {9},
year = {2002}
}
@article{Leng2014,
abstract = {Semi-supervised clustering which uses the limited labeled data to aid unsupervised clustering, has become a hot topic in recent years. But the limited labeled data may be imbalanced and can not cover all clusters in some cases and most of the existing semi-supervised clustering algorithms can not deal with imbalanced dataset well and have no the ability of detecting new clusters. In view of this, an adaptive semi-supervised clustering algorithm with label propagation is proposed. Two most of interesting characteristics of the proposed algorithm are that (1) It uses the limited labeled data to expand labeled dataset based on an adaptive threshold by labeling their k-nearest neighbors, (2) It detects whether there exist new clusters in the unlabeled dataset according to a proposed measure criterion. Three standard datasets are used to demonstrate the performance of the proposed algorithm and the experimental results confirm that the accuracy of the proposed clustering algorithm is much higher than that of three compared algorithm and in addition the proposed algorithm has the ability of detecting new clusters. {\textcopyright} 2014 Academic Journals Inc.},
author = {Leng, Mingwei and Wang, Jinjin and Cheng, Jianjun and Zhou, Hanhai and Chen, Xiaoyun},
doi = {10.3923/jse.2014.14.22},
file = {:C\:/Users/piotr/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Leng et al. - 2014 - Adaptive semi-supervised clustering algorithm with label propagation.pdf:pdf},
issn = {21520941},
journal = {Journal of Software Engineering},
keywords = {Data mining,K-nearest neighbors,Label propagation,Semi-supervised clustering},
number = {1},
pages = {14--22},
publisher = {Academic Journals},
title = {{Adaptive semi-supervised clustering algorithm with label propagation}},
volume = {8},
year = {2014}
}
@misc{PTSD,
author = {for PTSD, National Center},
title = {{Using the PTSD Checklist for DSM-5 (PCL-5) www.ptsd.va.gov}},
url = {http://www.ptsd.va.gov/professional/assessment/adult-sr/ptsd-checklist.asp},
urldate = {2022-09-26}
}
@article{Schumacher2000,
abstract = {In this article we will describe the evaluation of Antonovsky's 29-items Sense of Coherence Scale (SOC-29) in a large community sample (n = 2.005) of the German population and the development of the Leipzig Short Scale (SOC-L9), which consists of only 9 items. The SOC-29 has a high internal consistency ($\alpha$ = 0.92), however, the SOC-subscales (comprehensibility, manageability, meaningfulness) were correlated with each other. A principal component factor analysis did not identify the 3-factor structure of the SOC-Scale. It appears that the best solution consists of one global factor. The newly developed SOC-L9, conceptualized as an unidimensional scale, is a reliable and valid instrument, which allows to assess the SOC economically. In our study the Sense of Coherence depended on age and gender. Women and older people reported a lower SOC. Furthermore we found significant associations between SOC and different subjective health measures. A high SOC was associated with both a lower extent of subjective body complaints and somatoform symptoms and with minor health-related problems in daily living.},
author = {Schumacher, J. and Wilz, G. and Gunzelmann, T. and Br{\"{a}}hler, E.},
doi = {10.1055/s-2000-9207},
issn = {09372032},
journal = {PPmP Psychotherapie Psychosomatik Medizinische Psychologie},
keywords = {New short scale,Salutogenic model,Sense of Coherence Scale (SOC),Sense of coherence},
number = {12},
pages = {472--482},
pmid = {11199111},
publisher = {Psychother Psychosom Med Psychol},
title = {{Die sense of coherence scale von antonovsky: Teststatische {\"{u}}berpr{\"{u}}fung in einer repr{\"{a}}sentativen bev{\"{o}}lkerungsstichprobe und konstruktion einer kurzskala}},
url = {https://pubmed.ncbi.nlm.nih.gov/11199111/},
volume = {50},
year = {2000}
}
@article{Ribeiro2013,
abstract = {Background Violence and other traumatic events, as well as psychiatric disorders are frequent in developing countries, but there are few population studies to show the actual impact of traumatic events in the psychiatric morbidity in low and middle-income countries (LMIC).  Aims To study the relationship between traumatic events and prevalence of mental disorders in S{\~{a}}o Paulo and Rio de Janeiro, Brazil.  Methods Cross-sectional survey carried out in 2007–2008 with a probabilistic representative sample of 15- to 75-year-old residents in Sao Paulo and Rio de Janeiro, Brazil, using the Composite International Diagnostic Interview.  Results The sample comprised 3744 interviews. Nearly 90% of participants faced lifetime traumatic events. Lifetime prevalence of any disorders was 44% in Sao Paulo and 42.1% in Rio de Janeiro. One-year estimates were 32.5% and 31.2%. One-year prevalence of traumatic events was higher in Rio de Janeiro than Sao Paulo (35.1 vs. 21.7; p<0.001). Participants from Rio de Janeiro were less likely to have alcohol dependence (OR = 0.55; p = 0.027), depression (OR = 0.6; p = 0.006) generalized anxiety (OR = 0.59; p = 0.021) and post-traumatic stress disorder (OR = 0.62; p = 0.027). Traumatic events correlated with all diagnoses – e.g. assaultive violence with alcohol dependence (OR = 5.7; p<0.001) and with depression (OR = 1.7; p = 0.001).  Conclusion Our findings show that psychiatric disorders and traumatic events, especially violence, are extremely common in Sao Paulo and Rio de Janeiro, supporting the idea that neuropsychiatric disorders and external causes have become a major public health priority, as they are amongst the leading causes of burden of disease in low and middle-income countries. The comparison between the two cities regarding patterns of violence and psychiatric morbidity suggests that environmental factors may buffer the negative impacts of traumatic events. Identifying such factors might guide the implementation of interventions to improve mental health and quality of life in LMIC urban centers.},
author = {Ribeiro, Wagner Silva and Mari, Jair de Jesus and Quintana, Maria In{\^{e}}s and Dewey, Michael E. and Evans-Lacko, Sara and Vilete, Liliane Maria Pereira and Figueira, Ivan and Bressan, Rodrigo Affonseca and de Mello, Marcelo Feij{\'{o}} and Prince, Martin and Ferri, Cleusa P. and Coutinho, Evandro Silva Freire and Andreoli, S{\'{e}}rgio Baxter},
doi = {10.1371/JOURNAL.PONE.0063545},
issn = {1932-6203},
journal = {PLOS ONE},
keywords = {Alcoholism,Anxiety disorders,Brazil,Cities,Depression,Post-traumatic stress disorder,Traumatic injury,Urban areas},
month = {may},
number = {5},
pages = {e63545},
pmid = {23667636},
publisher = {Public Library of Science},
title = {{The Impact of Epidemic Violence on the Prevalence of Psychiatric Disorders in Sao Paulo and Rio de Janeiro, Brazil}},
url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0063545},
volume = {8},
year = {2013}
}
@article{Spitzer2006,
abstract = {Background Generalized anxiety disorder (GAD) is one of the most common mental disorders; however, there is no brief clinical measure for assessing GAD. The objective of this study was to develop a brief self-report scale to identify probable cases of GAD and evaluate its reliability and validity. Methods A criterion-standard study was performed in 15 primary care clinics in the United States from November 2004 through June 2005. Of a total of 2740 adult patients completing a study questionnaire, 965 patients had a telephone interview with a mental health professional within 1 week. For criterion and construct validity, GAD self-report scale diagnoses were compared with independent diagnoses made by mental health professionals; functional status measures; disability days; and health care use. Results A 7-item anxiety scale (GAD-7) had good reliability, as well as criterion, construct, factorial, and procedural validity. A cut point was identified that optimized sensitivity (89%) and specificity (82%). Increasing scores on the scale were strongly associated with multiple domains of functional impairment (all 6 Medical Outcomes Study Short-Form General Health Survey scales and disability days). Although GAD and depression symptoms frequently co-occurred, factor analysis confirmed them as distinct dimensions. Moreover, GAD and depression symptoms had differing but independent effects on functional impairment and disability. There was good agreement between self-report and interviewer-administered versions of the scale. Conclusion The GAD-7 is a valid and efficient tool for screening for GAD and assessing its severity in clinical practice and research.},
author = {Spitzer, Robert L. and Kroenke, Kurt and Williams, Janet B.W. and L{\"{o}}we, Bernd},
doi = {10.1001/ARCHINTE.166.10.1092},
issn = {0003-9926},
journal = {Archives of Internal Medicine},
keywords = {anxiety,depressive disorders,generalized anxiety disorder},
month = {may},
number = {10},
pages = {1092--1097},
pmid = {16717171},
publisher = {American Medical Association},
title = {{A Brief Measure for Assessing Generalized Anxiety Disorder: The GAD-7}},
url = {https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/410326},
volume = {166},
year = {2006}
}
@article{Vesanto2000,
abstract = {The self-organizing map (SOM) is an excellent tool in exploratory phase of data mining. It projects input space on prototypes of a low-dimensional regular grid that can be effectively utilized to visualize and explore properties of the data. When the number of SOM units is large, to facilitate quantitative analysis of the map and the data, similar units need to be grouped, i.e., clustered. In this paper, different approaches to clustering of the SOM are considered. In particular, the use of hierarchical agglomerative clustering and partitive clustering using k-means are investigated. The two-stage procedure-first using SOM to produce the prototypes that are then clustered in the second stage-is found to perform well when compared with direct clustering of the data and to reduce the computation time.},
author = {Vesanto, Juha and Alhoniemi, Esa},
doi = {10.1109/72.846731},
issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
month = {may},
number = {3},
pages = {586--600},
title = {{Clustering of the self-organizing map}},
volume = {11},
year = {2000}
}
@article{Leppert2008,
author = {Leppert, K and Koch, B and Br{\"{a}}hler, E and Und, B Strau{\ss} - Klinische Diagnostik and 2008, Undefined},
journal = {Klinische Diagnostik und Evaluation},
pages = {226--243},
title = {{Die Resilienzskala (RS)–{\"{U}}berpr{\"{u}}fung der Langform RS-25 und einer Kurzform RS-13}},
url = {https://www.academia.edu/download/44388154/A_406.pdf},
volume = {1},
year = {2008}
}
@misc{Konopka2022,
abstract = {Uniform manifold approximation and projection is a technique for dimension reduction. The algorithm was described by McInnes and Healy (2018) in <arXiv:1802.03426>. This package provides an interface for two implementations. One is written from scratch, including components for nearest-neighbor search and for embedding. The second implementation is a wrapper for 'python' package 'umap-learn' (requires separate installation, see vignette for more details).},
author = {Konopka, Tomasz},
title = {{umap: Uniform Manifold Approximation and Projection}},
url = {https://cran.r-project.org/web/packages/umap/index.html},
year = {2022}
}
@article{Wehrens2018,
abstract = {Self-organizing maps (SOMs) are popular tools for grouping and visualizing data in many areas of science. This paper describes recent changes in package kohonen, implementing several different forms of SOMs. These changes are primarily focused on making the package more useable for large data sets. Memory consumption has decreased dramatically, amongst others, by replacing the old interface to the underlying compiled code by a new one relying on Rcpp. The batch SOM algorithm for training has been added in both sequential and parallel forms. A final important extension of the package's repertoire is the possibility to define and use data-dependent distance functions, extremely useful in cases where standard distances like the Euclidean distance are not appropriate. Several examples of possible applications are presented.},
author = {Wehrens, Ron and Kruisselbrink, Johannes},
doi = {10.18637/jss.v087.i07},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {Distance functions,Parallellization, R.,Self-organizing maps},
month = {oct},
number = {7},
pages = {1--18},
publisher = {American Statistical Association},
title = {{Flexible self-organizing maps in kohonen 3.0}},
url = {https://www.jstatsoft.org/index.php/jss/article/view/v087i07/v87i07.pdf https://www.jstatsoft.org/index.php/jss/article/view/v087i07},
volume = {87},
year = {2018}
}
@article{Schmidt2006,
abstract = {Background: Survey research including multiple health indicators requires brief indices for use in cross-cultural studies, which have, however, rarely been tested in terms of their psychometric quality. Recently, the EUROHIS-QOL 8-item index was developed as an adaptation of the WHOQOL-100 and the WHOQOL-BREF. The aim of the current study was to test the psychometric properties of the EUROHIS-QOL 8-item index. Methods: In a survey on 4849 European adults, the EUROHIS-QOL 8-item index was assessed across 10 countries, with equal samples adjusted for selected sociodemographic data. Participants were also investigated with a chronic condition checklist, measures on general health perception, mental health, health-care utilization and social support. Results: Findings indicated good internal consistencies across a range of countries, showing acceptable convergent validity with physical and mental health measures, and the measure discriminates well between individuals that report having a longstanding condition and healthy individuals across all countries. Differential item functioning was less frequently observed in those countries that were geographically and culturally closer to the UK, but acceptable across all countries. A universal one-factor structure with a good fit in structural equation modelling analyses (SEM) was identified with, however, limitations in model fit for specific countires. Conclusions: The short EUROHIS-QOL 8-item index showed good cross-cultural field study performance and a satisfactory convergent and discriminant validity, and can therefore be recommended for use in public health research. In future studies the measure should also be tested in multinational clinical studies, particularly in order to test its sensitivity. {\textcopyright} The Author 2005. Published by Oxford University Press on behalf of the European Public Health Association. All rights reserved.},
author = {Schmidt, Silke and M{\"{u}}hlan, Holger and Power, Mick},
doi = {10.1093/EURPUB/CKI155},
issn = {1101-1262},
journal = {European Journal of Public Health},
keywords = {Cross-cultural,EUROHIS,Health indicator,Quality of life,Short version},
month = {aug},
number = {4},
pages = {420--428},
pmid = {16141303},
publisher = {Oxford Academic},
title = {{The EUROHIS-QOL 8-item index: psychometric results of a cross-cultural field study}},
url = {https://academic.oup.com/eurpub/article/16/4/420/644306},
volume = {16},
year = {2006}
}
@book{McDonald1999,
abstract = {This book introduces the reader to the main quantitative concepts, methods, and computational techniques needed for the development, evaluation, and application of tests in the behavioral/social sciences, including educational tests. Two empirical examples are carried throughout to illustrate alternative methods. Other data sets are used for special illustrations. Self-contained programs for confirmatory and exploratory factor analysis are available on the Web. Intended for students of psychology, particularly educational psychology, as well as social science students interested in how tests are constructed and used, prerequisites include a course on statistics.},
address = {New Yor},
author = {McDonald, Roderick P.},
booktitle = {Test Theory: A Unified Treatment},
doi = {10.4324/9781410601087},
edition = {1st Editio},
isbn = {9781410601087},
month = {jul},
pages = {1--485},
publisher = {Psychology Press},
title = {{Test theory: A unified treatment}},
url = {https://www.taylorfrancis.com/books/mono/10.4324/9781410601087/test-theory-roderick-mcdonald},
year = {1999}
}
@article{Drost2018,
abstract = {Comparison is a fundamental method of scientific research leading to insights about the processes that generate similarity or dissimilarity. In statistical terms comparisons between probability functions are performed to infer connections, correlations, or relationships between objects or samples (Cha 2007). Most quantification methods rely on distance or similarity measures, but the right choice for each individual application is not always clear and sometimes poorly explored. The reason for this is partly that diverse measures are either implemented in different R packages with very different notations or are not implemented at all. Thus, a comprehensive framework implementing the most common similarity and distance measures using a uniform notation is still missing. The R (R Core Team 2018) package Philentropy aims to fill this gap by implementing forty-six fundamental distance and similarity measures (Cha 2007) for comparing probability functions. These comparisons between probability functions have their foundations in a broad range of scientific disciplines from mathematics to ecology. The aim of this package is to provide a comprehensive and computationally optimized base framework for clustering, classification, statistical inference, goodness-of-fit, non-parametric statistics, information theory, and machine learning tasks that are based on comparing univariate or multivari-ate probability functions. All functions are written in C++ and are integrated into the R package using the Rcpp Application Programming Interface (API) (Eddelbuettel 2013). Together, this framework allows building new similarity or distance based (statistical) models and algorithms in R which are computationally efficient and scalable. The comprehensive availability of diverse metrics and measures furthermore enables a systematic assessment of choosing the most optimal similarity or distance measure for individual applications in diverse scientific disciplines. The following probability distance/similarity and information theory measures are implemented in Philentropy. Distance and Similarity Measures L p Minkowski Family • Euclidean : d = √ ∑ N i=1 |P i − Q i | 2) • Manhattan : d = ∑ N i=1 |P i − Q i | • Minkowski : d = (∑ N i=1 |P i − Q i | p) 1/p • Chebyshev : d = max|P i − Q i | L 1 Family • Sorensen : d = ∑ N i=1 |Pi−Qi| ∑ N i=1 (Pi+Qi) Drost, (2018). Philentropy: Information Theory and Distance Quantification with R. Journal of Open Source Software, 3(26), 765.},
author = {Drost, Hajk-Georg},
doi = {10.21105/joss.00765},
file = {:C\:/Users/piotr/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Drost - 2018 - Philentropy Information Theory and Distance Quantification with R.pdf:pdf},
issn = {2475-9066},
journal = {Journal of Open Source Software},
month = {jun},
number = {26},
pages = {765},
publisher = {The Open Journal},
title = {{Philentropy: Information Theory and Distance Quantification with R}},
url = {https://doi.org/10.21105/joss.00765},
volume = {3},
year = {2018}
}
@misc{Kassambara2020,
author = {Kassambara, Alboukadel and Mundt, Fabian},
title = {{factoextra: Extract and Visualize the Results of Multivariate Data Analyses}},
url = {https://cran.r-project.org/web/packages/factoextra/index.html},
year = {2020}
}
@article{Lange2004,
abstract = {Data clustering describes a set of frequently employed techniques in exploratory data analysis to extract "natural" group structure in data. Such groupings need to be validated to separate the signal in the data from spurious structure. In this context, finding an appropriate number of clusters is a particularly important model selection question. We introduce a measure of cluster stability to assess the validity of a cluster model. This stability measure quantifies the reproducibility of clustering solutions on a second sample, and it can be interpreted as a classification risk with regard to class labels produced by a clustering algorithm. The preferred number of clusters is determined by minimizing this classification risk as a function of the number of clusters. Convincing results are achieved on simulated as well as gene expression data sets. Comparisons to other methods demonstrate the competitive performance of our method and its suitability as a general validation tool for clustering solutions in real-world problems.},
author = {Lange, Tilman and Roth, Volker and Braun, Mikio L. and Buhmann, Joachim M.},
doi = {10.1162/089976604773717621},
issn = {08997667},
journal = {Neural Computation},
month = {jun},
number = {6},
pages = {1299--1323},
pmid = {15130251},
publisher = {MIT Press},
title = {{Stability-based validation of clustering solutions}},
volume = {16},
year = {2004}
}
@article{OBrien2008,
abstract = {Four clinical interview questions, the CAGE questions, have proved useful in helping to make a diagnosis of alcoholism. The questions focus on Cutting down, Annoyance by criticism, Guilty feeling, and Eye-openers. The acronym “CAGE” helps the physician to recall the questions.How these questions were identified and their use in clinical and research studies are described.See PDF for full text of the original JAMA article.},
author = {O'Brien, Charles P.},
doi = {10.1001/JAMA.2008.570},
issn = {0098-7484},
journal = {JAMA},
keywords = {alcohol dependence,alcohol use test},
month = {nov},
number = {17},
pages = {2054--2056},
pmid = {18984895},
publisher = {American Medical Association},
title = {{The CAGE Questionnaire for Detection of Alcoholism}},
url = {https://jamanetwork.com/journals/jama/fullarticle/182810},
volume = {300},
year = {2008}
}
@misc{RCoreTeam,
abstract = {Reading and writing data stored by some versions of 'Epi Info', 'Minitab', 'S', 'SAS', 'SPSS', 'Stata', 'Systat', 'Weka', and for reading and writing some 'dBase' files.},
author = {{R Core Team} and Bivand, Roger and Carey, Vincent J and DebRoy, Saikat and Eglen, Stephen and Guha, Rajarshi and Herbrandt, Swetlana and Lewin-Koh, Nicholas and Myatt, Mark and Nelson, Michael and Pfaff, Ben and Quistorff, Brian and Warmerdam, Frank and Weigand, Stephen and {Free Software Foundation}, Inc.},
title = {{foreign: Read Data Stored by 'Minitab', 'S', 'SAS', 'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ...}},
url = {https://cran.r-project.org/web/packages/foreign/index.html},
year = {2022}
}
@article{Becht2018,
abstract = {Advances in single-cell technologies have enabled high-resolution dissection of tissue composition. Several tools for dimensionality reduction are available to analyze the large number of parameters generated in single-cell studies. Recently, a nonlinear dimensionality-reduction technique, uniform manifold approximation and projection (UMAP), was developed for the analysis of any type of high-dimensional data. Here we apply it to biological data, using three well-characterized mass cytometry and single-cell RNA sequencing datasets. Comparing the performance of UMAP with five other tools, we find that UMAP provides the fastest run times, highest reproducibility and the most meaningful organization of cell clusters. The work highlights the use of UMAP for improved visualization and interpretation of single-cell data.},
author = {Becht, Etienne and McInnes, Leland and Healy, John and Dutertre, Charles Antoine and Kwok, Immanuel W.H. and Ng, Lai Guan and Ginhoux, Florent and Newell, Evan W.},
doi = {10.1038/nbt.4314},
issn = {15461696},
journal = {Nature Biotechnology},
keywords = {Computational biology and bioinformatics,Data mining,Immunology},
month = {dec},
number = {1},
pages = {38--47},
pmid = {30531897},
publisher = {Nature Publishing Group},
title = {{Dimensionality reduction for visualizing single-cell data using UMAP}},
url = {https://www.nature.com/articles/nbt.4314},
volume = {37},
year = {2019}
}
